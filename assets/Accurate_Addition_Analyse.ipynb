{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Accurate Integer Addition in Transformers - Analyse the Model\n",
        "\n",
        "This CoLab analyses a Transformer model that performs integer addition e.g. 33357+82243=115600. Each digit is a separate token. For 5 digit addition, the model is given 12 \"question\" (input) tokens, and must then predict the corresponding 6 \"answer\" (output) tokens.\n",
        "\n",
        "For speed, this CoLab relies on the model weightings created by the sister CoLab [Accurate_Addition_Train](https://github.com/PhilipQuirke/transformer-maths/blob/main/assets/Accurate_Addition_Train.ipynb). These model weightings are loaded from HuggingFace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1: Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmjGdFcdJat3"
      },
      "outputs": [],
      "source": [
        "# Tokens used in vocab. (Token indexes 0 to 9 represent digits 0 to 9)\n",
        "PLUS_INDEX = 10\n",
        "MINUS_INDEX = 11\n",
        "EQUALS_INDEX = 12\n",
        "\n",
        "class Config():\n",
        "  #@markdown Model\n",
        "  n_layers: int = 2 #@param\n",
        "  n_heads: int = 3 #@param\n",
        "\n",
        "  d_vocab: int = EQUALS_INDEX+1\n",
        "  d_model: int = ( 512 // n_heads ) * n_heads # About 512, and divisible by n_heads\n",
        "  d_mlp: int = 4 * d_model\n",
        "  d_head: int = d_model // n_heads  # About 170 when n_heads == 3\n",
        "  seed: int = 129000 #@param\n",
        "\n",
        "  #@markdown Data\n",
        "  n_digits: int = 5 #@param\n",
        "  n_ctx: int = 3 * n_digits + 3\n",
        "  act_fn: str = 'relu'\n",
        "  batch_size: int = 64 #@param\n",
        "\n",
        "  #@markdown Optimizer\n",
        "  n_training_steps: int = 30000 #@param\n",
        "  lr: float = 0.00008 #@param\n",
        "  weight_decay: int = 0.1 #@param\n",
        "\n",
        "  # Save graphs to CoLab temp files as PDF and HTML. Can manually export files for re-use in papers.\n",
        "  save_graph_to_file: bool = True\n",
        "\n",
        "  # The format to output prettytable in. Options are text|html|json|csv|latex\n",
        "  # Use Text for this CoLab, latex for Overleaf output, and html for GitHub blog output\n",
        "  table_out_format: str = \"text\"\n",
        "\n",
        "\n",
        "cfg = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRl02gCb30y-"
      },
      "outputs": [],
      "source": [
        "def file_name_suffix(digits, layers, heads, d_model, d_head, ctx, seed, training_steps):\n",
        "  epoch_str = str(training_steps//1000) + \"K\"\n",
        "  return '_d{}_l{}_h{}_dm{}_dh{}_ctx{}_seed{}_train{}'.format(digits, layers, heads, d_model, d_head, ctx, seed, epoch_str)\n",
        "\n",
        "op_prefix = 'add'\n",
        "fname_prefix = op_prefix\n",
        "main_fname_suffix = fname_prefix + file_name_suffix(cfg.n_digits, cfg.n_layers, cfg.n_heads, cfg.d_model, cfg.d_head, cfg.n_ctx, cfg.seed, cfg.n_training_steps)\n",
        "main_fname_full = main_fname_suffix + '.pth'\n",
        "\n",
        "\n",
        "def print_config():\n",
        "  print(\"Config:\", main_fname_suffix)\n",
        "\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 2: Import libraries\n",
        "Imports standard libraries. Don't bother reading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCdmr6-_Jkzi"
      },
      "outputs": [],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    !pip install matplotlib\n",
        "    !pip install prettytable\n",
        "\n",
        "    !pip install kaleido\n",
        "    !pip install transformer_lens\n",
        "    !pip install torchtyping\n",
        "    !pip install transformers\n",
        "\n",
        "    !pip install numpy -- upgrade\n",
        "    !pip install scikit-learn -- upgrade\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from prettytable import PrettyTable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import textwrap\n",
        "\n",
        "# Use Principal Component Analysis (PCA) library\n",
        "use_pca = True\n",
        "try:\n",
        "  from sklearn.decomposition import PCA\n",
        "except Exception as e:\n",
        "  print(\"pca import exception:\", e)\n",
        "  use_pca = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VQ4e0QJsIB"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RfHXneJw6n"
      },
      "source": [
        "# Part 3: Create model\n",
        "This section defines the token embedding / unembedding and creates the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QYFZIalJ3tK"
      },
      "outputs": [],
      "source": [
        "# Embedding / Unembedding\n",
        "\n",
        "def token_to_char(i):\n",
        "  if i < 10:\n",
        "   return str(i)\n",
        "  if i == PLUS_INDEX:\n",
        "    return \"+\"\n",
        "  if i == MINUS_INDEX:\n",
        "    return \"-\"\n",
        "  if i == EQUALS_INDEX:\n",
        "    return \"=\"\n",
        "  return \"?\"\n",
        "\n",
        "\n",
        "def tokens_to_string(tokens):\n",
        "    tokens = utils.to_numpy(tokens)\n",
        "    return \"\".join([token_to_char(i) for i in tokens[:cfg.n_ctx]])\n",
        "\n",
        "\n",
        "def string_to_tokens(string, batch: bool=False):\n",
        "    lookup = {str(i):i for i in range(10)}\n",
        "    lookup['+']=PLUS_INDEX\n",
        "    lookup['-']=MINUS_INDEX\n",
        "    lookup['=']=EQUALS_INDEX\n",
        "\n",
        "    tokens = [lookup[i] for i in string if i not in '\\n ']\n",
        "    if batch:\n",
        "        return torch.tensor(tokens)[None, :]\n",
        "    else:\n",
        "        return torch.tensor(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA16Nb2PJ7MB"
      },
      "outputs": [],
      "source": [
        "# Transformer creation\n",
        "\n",
        "# Structure is documented at https://neelnanda-io.github.io/TransformerLens/transformer_lens.html#transformer_lens.HookedTransformerConfig.HookedTransformerConfig\n",
        "ht_cfg = HookedTransformerConfig(\n",
        "    n_layers = cfg.n_layers,\n",
        "    n_heads = cfg.n_heads,\n",
        "    d_model = cfg.d_model,\n",
        "    d_head = cfg.d_head,\n",
        "    d_mlp = cfg.d_mlp,\n",
        "    act_fn = cfg.act_fn,\n",
        "    normalization_type = 'LN',\n",
        "    d_vocab = cfg.d_vocab,\n",
        "    d_vocab_out = cfg.d_vocab,\n",
        "    n_ctx = cfg.n_ctx,\n",
        "    init_weights = True,\n",
        "    device = \"cuda\",\n",
        "    seed = cfg.seed,\n",
        ")\n",
        "\n",
        "model = HookedTransformer(ht_cfg)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                        lr = cfg.lr,\n",
        "                        weight_decay = cfg.weight_decay,\n",
        "                        betas = (0.9, 0.98))\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(step/10, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHiJhch4KCej"
      },
      "source": [
        "# Part 4: Data Generator. Addition sub-task categorisation\n",
        "This section defines the loss function and the training/tesing data generator.\n",
        "\n",
        "It also defines functions to categorise the training data by the addition sub-task defined in the paper. The addition sub tasks are abbreviated as:\n",
        "- BA is Base Add. Calculates the sum of two digits Dn and Dn' modulo 10, ignoring any carry over from previous columns.\n",
        "- MC1 is Make Carry 1. Evaluates to true if adding digits Dn and Dn' results in a carry over of 1 to the next column.\n",
        "- MS9 is Make Sum 9. Evaluates to true if adding digits Dn and Dn' gives exactly 9.\n",
        "- UC1 is Use Carry 1. Takes the previous column's carry output and adds it to the sum of the current digit pair.\n",
        "- US9 is Use Sum 9. Propagates (aka cascades) a carry over of 1 to the next column if the current column sums to 9 and the previous column generated a carry over. US9 is the most complex task as it spans three digits. For some rare questions (e.g. 00555 + 00445 = 01000) US9 applies to up to four sequential digits, causing a chain effect, with the MC1 cascading through multiple digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ2iNO-nKDBW"
      },
      "outputs": [],
      "source": [
        "# Loss functions\n",
        "\n",
        "# Calculate the per-token probability by comparing a batch of prediction \"logits\" to answer \"tokens\"\n",
        "def logits_to_tokens_loss(logits, tokens):\n",
        "\n",
        "  # The last \"n_digit+1\" tokens are the addition answer probabilities\n",
        "  ans_logits = logits[:, -(cfg.n_digits+2) :-1]\n",
        "\n",
        "  # Convert raw score (logits) vector into a probability distribution.\n",
        "  # Emphasize the largest scores and suppress the smaller ones, to make them more distinguishable.\n",
        "  ans_probs = F.log_softmax(ans_logits.to(torch.float64), dim=-1)\n",
        "\n",
        "  max_indices = torch.argmax(ans_probs, dim=-1)\n",
        "\n",
        "  # The last \"n_digit+1\" tokens are the modelâ€™s answer.\n",
        "  ans_tokens = tokens[:, -(cfg.n_digits+1):]\n",
        "\n",
        "  # Extract values from the ans_probs tensor, based on indices from the ans_tokens tensor\n",
        "  ans_loss = torch.gather(ans_probs, -1, ans_tokens[:, :, None])[..., 0]\n",
        "\n",
        "  return ans_loss, max_indices\n",
        "\n",
        "\n",
        "# Calculate loss as negative of average per-token mean probability\n",
        "def loss_fn(ans_loss):\n",
        "  return -ans_loss.mean(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSp8pS1eKHf6"
      },
      "outputs": [],
      "source": [
        "# Define \"iterator\" data generator function. Invoked using next().\n",
        "# \"Addition\" batch entries are formated XXXXX+YYYYY=ZZZZZZ e.g. 55003+80002=135005\n",
        "# \"Subtraction\" batch entries are formated XXXXX-YYYYY=ZZZZZZ e.g. 55003-80002=-24999, 80002-55003=024999\n",
        "# Note that answer has one more digit than the question\n",
        "# Returns characteristics of each batch entry to aid later analysis\n",
        "def data_generator():\n",
        "    torch.manual_seed(cfg.seed)\n",
        "    while True:\n",
        "        #generate a batch of questions (answers calculated below)\n",
        "        batch = torch.zeros((cfg.batch_size, cfg.n_ctx)).to(torch.int64)\n",
        "        x = torch.randint(0, 10, (cfg.batch_size, cfg.n_digits))\n",
        "        y = torch.randint(0, 10, (cfg.batch_size, cfg.n_digits))\n",
        "\n",
        "\n",
        "        # The UseSum9 task is compound and rare and so hard to learn.\n",
        "        # For some batches, we increase the MakeSum9 case frequency\n",
        "        # UseSum9 also relies on MakeCarry1 (50%) from previous column.\n",
        "        # So UseSum9 frequency is increased by 60% * 40% * 50% = 12%\n",
        "        if random.randint(1, 5) < 3: # 60%\n",
        "          # Flatten x and y to 1D tensors\n",
        "          x_flat = x.view(-1)\n",
        "          y_flat = y.view(-1)\n",
        "\n",
        "          num_elements_to_modify = int(0.40 * x.numel()) # 40%\n",
        "          indices_to_modify = torch.randperm(x_flat.numel())[:num_elements_to_modify]\n",
        "          if random.randint(1, 2) == 1:\n",
        "            x_flat[indices_to_modify] = 9 - y_flat[indices_to_modify]\n",
        "          else:\n",
        "            y_flat[indices_to_modify] = 9 - x_flat[indices_to_modify]\n",
        "\n",
        "          # Reshape x and y back to its original shape\n",
        "          x = x_flat.view(x.shape)\n",
        "          y = y_flat.view(x.shape)\n",
        "\n",
        "\n",
        "        batch[:, :cfg.n_digits] = x\n",
        "        batch[:, cfg.n_digits] = PLUS_INDEX\n",
        "        batch[:, 1+cfg.n_digits:1+cfg.n_digits*2] = y\n",
        "        batch[:, 1+cfg.n_digits*2] = EQUALS_INDEX\n",
        "\n",
        "        # These attributes are used for testing addition\n",
        "        base_adds = torch.zeros((cfg.batch_size,cfg.n_digits)).to(torch.int64)\n",
        "        make_carry1s = torch.zeros((cfg.batch_size,cfg.n_digits)).to(torch.int64)\n",
        "        sum9s = torch.zeros((cfg.batch_size,cfg.n_digits)).to(torch.int64)\n",
        "        use_carry1s = torch.zeros((cfg.batch_size,cfg.n_digits)).to(torch.int64)\n",
        "        use_sum9s = torch.zeros((cfg.batch_size,cfg.n_digits)).to(torch.int64)\n",
        "\n",
        "        # generate the addition question answers & other info for testing\n",
        "        for i in range(cfg.n_digits):\n",
        "            # the column in the test attributes being updated\n",
        "            test_col = cfg.n_digits-1-i\n",
        "\n",
        "            base_add = batch[:, cfg.n_digits-1-i] + batch[:, 2*cfg.n_digits-i]\n",
        "            base_adds[:, test_col] = base_add % 10\n",
        "\n",
        "            sum9 = (base_add == 9)\n",
        "            sum9s[:, test_col] = sum9\n",
        "\n",
        "            if i>0:\n",
        "              use_carry1s[:, test_col] = make_carry1s[:, test_col+1]\n",
        "            use_carry = use_carry1s[:, test_col]\n",
        "\n",
        "            use_sum9s[:, test_col] = sum9 & use_carry;\n",
        "\n",
        "            digit_sum = base_add + use_carry1s[:, test_col]\n",
        "\n",
        "            make_carry = (digit_sum >= 10)\n",
        "            make_carry1s[:, test_col] = make_carry\n",
        "\n",
        "            batch[:, -1-i] = (digit_sum % 10)\n",
        "\n",
        "        # Final (possible) carry to highest digit of the sum\n",
        "        batch[:, -1-cfg.n_digits] = make_carry1s[:, 0]\n",
        "\n",
        "        yield batch.cuda(), base_adds.cuda(), make_carry1s.cuda(), sum9s.cuda(), use_carry1s.cuda(), use_sum9s.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqzljhQ4KJU5"
      },
      "outputs": [],
      "source": [
        "ds = data_generator()\n",
        "\n",
        "tokens, base_adds, make_carry1s, sum9s, use_carry1s, use_sum9s = next(ds)\n",
        "\n",
        "print(tokens[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KJhCxFtNKfm"
      },
      "source": [
        "# Part 5: Load Model from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRMkB_8GNRc0"
      },
      "outputs": [],
      "source": [
        "print(\"Loading model\", main_fname_full)\n",
        "\n",
        "model.load_state_dict(utils.download_file_from_hf(repo_name=\"PhilipQuirke/Accurate5DigitAddition\", file_name=main_fname_full, force_is_torch=True))\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGxoBWHNKRf0"
      },
      "source": [
        "# Part 8: Sample Questions Set Up\n",
        "\n",
        "Create sets of sample questions (by task) to ask the model to predict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mathematical operations\n",
        "addition_major_tag = \"Add\"\n",
        "subtraction_major_tag = \"Sub\"\n",
        "multiplication_major_tag = \"Mult\"\n",
        "varied_major_tag = \"Varied\"\n",
        "\n",
        "# Answer digit impact\n",
        "impact_major_tag = \"Impact\"\n",
        "\n",
        "# Ablation failure percentage\n",
        "perc_major_tag = \"FailPerc\"\n",
        "\n",
        "# Attention pattern\n",
        "attention_major_tag = \"Attn\""
      ],
      "metadata": {
        "id": "PjlXXr61Gor2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj_xSuSSKR9t"
      },
      "outputs": [],
      "source": [
        "# Insert a number into the question\n",
        "def insert_question_number(the_question, index, first_digit_index, the_digits, n):\n",
        "\n",
        "  last_digit_index = first_digit_index + the_digits - 1\n",
        "\n",
        "  for j in range(the_digits):\n",
        "    the_question[index, last_digit_index-j] = n % 10\n",
        "    n = n // 10\n",
        "\n",
        "\n",
        "# Create a single question\n",
        "def make_a_question(the_question, index, q1, q2):\n",
        "  a = q1 + q2\n",
        "\n",
        "  insert_question_number(the_question, index, 0, cfg.n_digits, q1)\n",
        "\n",
        "  the_question[index, cfg.n_digits] = PLUS_INDEX\n",
        "\n",
        "  insert_question_number( the_question, index, cfg.n_digits+1, cfg.n_digits, q2)\n",
        "\n",
        "  the_question[index, 2*cfg.n_digits+1] = EQUALS_INDEX\n",
        "  offset = 2\n",
        "\n",
        "  insert_question_number(the_question, index, 2*cfg.n_digits + offset, cfg.n_digits+1, q1+q2)\n",
        "\n",
        "\n",
        "# Create a batch of questions from a 2D matrix of ints\n",
        "def make_questions(q_matrix):\n",
        "  max_len = len(q_matrix)\n",
        "  real_len = 0\n",
        "  questions = torch.zeros((max_len, cfg.n_ctx)).to(torch.int64)\n",
        "  limit = 10 ** cfg.n_digits\n",
        "\n",
        "  for i in range(max_len):\n",
        "    a = q_matrix[i][0]\n",
        "    b = q_matrix[i][1]\n",
        "\n",
        "    if a < limit and b < limit:\n",
        "      make_a_question(questions, real_len, a, b)\n",
        "      real_len += 1\n",
        "\n",
        "  return questions[:real_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRCPyETTKaEs"
      },
      "outputs": [],
      "source": [
        "# Manually create some questions that strongly test one use case\n",
        "\n",
        "\n",
        "def make_s0_questions():\n",
        "    return make_questions(\n",
        "      [[12345, 33333],\n",
        "      [33333, 12345],\n",
        "      [45762, 33113],\n",
        "      [888, 11111],\n",
        "      [2362, 23123],\n",
        "      [15, 81],\n",
        "      [1000, 4440],\n",
        "      [4440, 1000],\n",
        "      [24033, 25133],\n",
        "      [23533, 21133],\n",
        "      [32500, 1],\n",
        "      [31500, 1111],\n",
        "      [5500, 12323],\n",
        "      [4500, 2209],\n",
        "      [ 33345, 66643], # =099988\n",
        "      [ 66643, 33345], # =099988\n",
        "      [10990, 44000],\n",
        "      [60000, 30000],\n",
        "      [10000, 20000]])\n",
        "\n",
        "\n",
        "def make_s1_questions():\n",
        "    return make_questions(\n",
        "      [[ 15, 45],\n",
        "      [ 25, 55],\n",
        "      [ 35, 59],\n",
        "      [ 40035, 40049],\n",
        "      [ 5025, 5059],\n",
        "      [ 15, 65],\n",
        "      [ 44000, 46000],\n",
        "      [ 70000, 40000],\n",
        "      [ 15000, 25000],\n",
        "      [ 35000, 35000],\n",
        "      [ 45000, 85000],\n",
        "      [ 67000, 85000],\n",
        "      [ 99000, 76000],\n",
        "      [ 1500, 4500],\n",
        "      [ 2500, 5500],\n",
        "      [ 3500, 5900],\n",
        "      [ 15020, 45091],\n",
        "      [ 25002, 55019],\n",
        "      [ 35002, 59019]])\n",
        "\n",
        "\n",
        "# These are one level UseSum9 cascades\n",
        "def make_s2_questions():\n",
        "    return make_questions(\n",
        "      [[ 55, 45],\n",
        "      [ 45, 55],\n",
        "      [ 45, 59],\n",
        "      [ 35, 69],\n",
        "      [ 25, 79],\n",
        "      [ 15, 85],\n",
        "      [ 15, 88],\n",
        "      [ 15508, 14500],\n",
        "      [ 14508, 15500],\n",
        "      [ 24533, 25933],\n",
        "      [ 23533, 26933],\n",
        "      [ 32500, 7900],\n",
        "      [ 31500, 8500],\n",
        "      [ 550, 450],\n",
        "      [ 450, 550],\n",
        "      [ 10880, 41127],\n",
        "      [ 41127, 10880],\n",
        "      [ 12386, 82623]])\n",
        "\n",
        "\n",
        "# These are two level UseSum9 cascades\n",
        "def make_s3_questions():\n",
        "    return make_questions(\n",
        "      [[ 555, 445],\n",
        "      [ 3340, 6660],\n",
        "      [ 8880, 1120],\n",
        "      [ 1120, 8880],\n",
        "      [ 123, 877],\n",
        "      [ 877, 123],\n",
        "      [ 321, 679],\n",
        "      [ 679, 321],\n",
        "      [ 1283, 78785]])\n",
        "\n",
        "\n",
        "# These are three level UseSum9 cascades\n",
        "def make_s4_questions():\n",
        "    return make_questions(\n",
        "      [[ 5555, 4445],\n",
        "      [ 55550, 44450],\n",
        "      [ 3334, 6666],\n",
        "      [ 33340, 66660],\n",
        "      [ 8888, 1112],\n",
        "      [ 88880, 11120],\n",
        "      [ 1234, 8766],\n",
        "      [ 4321, 5679]])\n",
        "\n",
        "\n",
        "# These are four level UseSum9 cascades\n",
        "def make_s5_questions():\n",
        "    return make_questions(\n",
        "      [[ 44445, 55555],\n",
        "      [ 33334, 66666],\n",
        "      [ 88888, 11112],\n",
        "      [ 12345, 87655],\n",
        "      [ 54321, 45679],\n",
        "      [ 45545, 54455],\n",
        "      [ 36634, 63366],\n",
        "      [ 81818, 18182],\n",
        "      [ 87345, 12655],\n",
        "      [ 55379, 44621]])\n",
        "\n",
        "\n",
        "# These questions focus mainly on 1 digit at a time\n",
        "# (We're assuming that the 0 + 0 digit additions are trivial bigrams)\n",
        "def make_sn_questions():\n",
        "    return make_questions(\n",
        "      [[ 1, 0],\n",
        "      [ 4, 3],\n",
        "      [ 5, 5],\n",
        "      [ 8, 1],\n",
        "      [ 40, 30],\n",
        "      [ 44, 46],\n",
        "      [ 400, 300],\n",
        "      [ 440, 460],\n",
        "      [ 800, 100],\n",
        "      [ 270, 470],\n",
        "      [ 600, 300],\n",
        "      [ 4000, 3000],\n",
        "      [ 4400, 4600],\n",
        "      [ 6000, 3000],\n",
        "      [ 7000, 4000],\n",
        "      [ 40000, 30000],\n",
        "      [ 44000, 46000],\n",
        "      [ 60000, 30000],\n",
        "      [ 70000, 40000],\n",
        "      [ 10000, 20000],\n",
        "      [ 15000, 25000],\n",
        "      [ 35000, 35000],\n",
        "      [ 45000, 85000],\n",
        "      [ 67000, 85000],\n",
        "      [ 99000, 76000],\n",
        "      [ 76000, 99000]])\n",
        "\n",
        "\n",
        "# Returns 128 random and ~100 manually-chosen questions\n",
        "def make_varied_questions():\n",
        "  q0, _, _, _, _, _ = next(ds)\n",
        "  q1 = make_s0_questions()\n",
        "  q2 = make_s1_questions()\n",
        "  q3 = make_s2_questions()\n",
        "  q4 = make_s3_questions()\n",
        "  q5 = make_s4_questions()\n",
        "  q6 = make_s5_questions()\n",
        "  q7 = make_sn_questions()\n",
        "  q8, _, _, _, _, _ = next(ds)\n",
        "\n",
        "  questions = torch.vstack((q0.cuda(), q1.cuda(), q2.cuda(), q3.cuda(), q4.cuda(), q5.cuda(), q6.cuda(), q7.cuda(), q8.cuda()))\n",
        "\n",
        "  return questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaLJysTzs_vM"
      },
      "outputs": [],
      "source": [
        "# 5 digit addition yields a 6 digit answer. Hence cfg.n_digits+1\n",
        "def get_answer(q):\n",
        "  a = 0\n",
        "  for j in range(cfg.n_digits+1):\n",
        "    a = a * 10 + q[cfg.n_digits*2 + 2 + j]\n",
        "  return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E56siA_QKe0W"
      },
      "outputs": [],
      "source": [
        "num_questions = 0;\n",
        "correct_answers = 0;\n",
        "verbose = True\n",
        "total_mean_loss = 0.0\n",
        "\n",
        "\n",
        "# Clear the question summary results\n",
        "def clear_questions_results(title):\n",
        "  global num_questions\n",
        "  global correct_answers\n",
        "  global verbose\n",
        "  global total_mean_loss\n",
        "\n",
        "  num_questions = 0\n",
        "  correct_answers = 0\n",
        "  total_mean_loss = 0\n",
        "\n",
        "  if verbose:\n",
        "    print(title)\n",
        "\n",
        "\n",
        "# Ask model to predict answer for each question & collect results\n",
        "def do_questions(questions):\n",
        "    global num_questions\n",
        "    global correct_answers\n",
        "    global verbose\n",
        "    global total_mean_loss\n",
        "\n",
        "    # Get model predictions with no hook\n",
        "    all_logits = model(questions.cuda())\n",
        "    all_losses_raw, all_max_indices = logits_to_tokens_loss(all_logits, questions.cuda())\n",
        "\n",
        "    num_questions = questions.shape[0]\n",
        "    for question_num in range(num_questions):\n",
        "      q = questions[question_num]\n",
        "\n",
        "      mean_loss = utils.to_numpy(loss_fn(all_losses_raw[question_num]).mean())\n",
        "      total_mean_loss = total_mean_loss + mean_loss\n",
        "\n",
        "      model_answer_str = tokens_to_string(all_max_indices[question_num])\n",
        "      model_answer_num = int(model_answer_str)\n",
        "\n",
        "      a = get_answer(q)\n",
        "\n",
        "      correct = (model_answer_num == a)\n",
        "      if correct :\n",
        "        correct_answers += 1\n",
        "\n",
        "      if verbose:\n",
        "        print(tokens_to_string(q), \"ModelAnswer:\", model_answer_str, \"Correct:\", correct, \"Loss:\", mean_loss )\n",
        "\n",
        "\n",
        "# Print the question summary results\n",
        "def print_questions_results(prefix, output_table):\n",
        "  global num_questions\n",
        "  global correct_answers\n",
        "  global total_mean_loss\n",
        "\n",
        "  output_table.add_row([prefix, num_questions, str(correct_answers), 100*correct_answers/num_questions, total_mean_loss/num_questions])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RHrsjKqKhR4"
      },
      "outputs": [],
      "source": [
        "# Build a test batch of 64 random and ~100 manually-chosen questions\n",
        "varied_questions = make_varied_questions();\n",
        "\n",
        "\n",
        "# Run the sample batch, gather the cache\n",
        "model.reset_hooks()\n",
        "model.set_use_attn_result(True)\n",
        "sample_logits, sample_cache = model.run_with_cache(varied_questions.cuda())\n",
        "print(sample_cache) # Gives names of datasets in the cache\n",
        "sample_losses_raw, sample_max_indices = logits_to_tokens_loss(sample_logits, varied_questions.cuda())\n",
        "sample_loss_mean = utils.to_numpy(loss_fn(sample_losses_raw).mean())\n",
        "print(\"Sample Mean Loss\", sample_loss_mean) # Loss < 0.04 is good\n",
        "\n",
        "\n",
        "# attn.hook_z is the \"attention head output\" hook point name (at a specified layer)\n",
        "l_attn_hook_z_name = [utils.get_act_name('z', 0, 'a'),utils.get_act_name('z', 1, 'a')] # 'blocks.0.attn.hook_z' etc\n",
        "sample_attn_z = sample_cache[l_attn_hook_z_name[0]]\n",
        "print(\"Sample\", l_attn_hook_z_name[0], sample_attn_z.shape) # gives [239, 18, 3, 170] = #questions, cfg.n_ctx, n_heads, d_head\n",
        "mean_attn_z = torch.mean(sample_attn_z, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_attn_hook_z_name[0], mean_attn_z.shape) # gives [1, 18, 3, 170] = 1, cfg.n_ctx, n_heads, d_head\n",
        "\n",
        "\n",
        "# hook_resid_pre is the \"pre residual memory update\" hook point name (at a specified layer)\n",
        "l_hook_resid_pre_name = ['blocks.0.hook_resid_pre','blocks.1.hook_resid_pre']\n",
        "\n",
        "\n",
        "# hook_resid_post is the \"post residual memory update\" hook point name (at a specified layer)\n",
        "l_hook_resid_post_name = ['blocks.0.hook_resid_post','blocks.1.hook_resid_post']\n",
        "sample_resid_post = sample_cache[l_hook_resid_post_name[0]]\n",
        "print(\"Sample\", l_hook_resid_post_name[0], sample_resid_post.shape) # gives [239, 18, 510] = #questions, cfg.n_ctx, cfg.d_model\n",
        "mean_resid_post = torch.mean(sample_resid_post, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_hook_resid_post_name[0], mean_resid_post.shape) # gives [1, 18, 510] = 1, cfg.n_ctx, d_model\n",
        "\n",
        "\n",
        "l_mlp_hook_pre_name = [utils.get_act_name('pre', 0),utils.get_act_name('pre', 1)] # 'blocks.0.mlp.hook_pre' etc\n",
        "\n",
        "\n",
        "# mlp.hook_post is the \"MLP layer\" hook point name (at a specified layer)\n",
        "l_mlp_hook_post_name = [utils.get_act_name('post', 0),utils.get_act_name('post', 1)] # 'blocks.0.mlp.hook_post' etc\n",
        "sample_mlp_hook_post = sample_cache[l_mlp_hook_post_name[0]]\n",
        "print(\"Sample\", l_mlp_hook_post_name[0], sample_mlp_hook_post.shape) # gives [239, 18, 2040] = #questions, cfg.n_ctx, cfg.d_mlp\n",
        "mean_mlp_hook_post = torch.mean(sample_mlp_hook_post, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_mlp_hook_post_name[0], mean_mlp_hook_post.shape) # gives [1, 18, 2040] = 1, cfg.n_ctx, cfg.d_mlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lag8C3d_KkeQ"
      },
      "source": [
        "# Part 9: Prediction Analysis By Use Case\n",
        "This section sets up BA, UC1 and US9 test cases that will be re-used in later experiments to show the impact of ablating heads or token positions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exp0_output = PrettyTable()\n",
        "exp0_output.field_names = [\"Case\", \"#Questions\", \"#Correct\", \"%Correct\", \"Mean loss\"]\n",
        "verbose = False"
      ],
      "metadata": {
        "id": "xaPIELSRUtfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_total_mean_loss = 0\n",
        "sum_num_questions = 0\n",
        "\n",
        "\n",
        "def print_question_results( title1, title2, questions):\n",
        "  global sum_total_mean_loss\n",
        "  global sum_num_questions\n",
        "\n",
        "  clear_questions_results(title1)\n",
        "  do_questions(questions)\n",
        "  print_questions_results(title2, exp0_output)\n",
        "  sum_total_mean_loss += total_mean_loss\n",
        "  sum_num_questions += num_questions"
      ],
      "metadata": {
        "id": "0iv6gwa0Qc7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z6RdolRKnnR"
      },
      "outputs": [],
      "source": [
        "print_question_results(\"Simple BaseAdd cases\", \"Add.S0\", make_s0_questions())\n",
        "print_question_results(\"These are Use Carry 1 (UC1) examples (not UseSum9 examples)\", \"Add.S1\", make_s1_questions())\n",
        "print_question_results(\"These are simple (one level) UseSum9 exampless\", \"Add.S2\", make_s2_questions())\n",
        "print_question_results(\"These are UseSum9 two level cascades\", \"Add.S3\", make_s3_questions())\n",
        "print_question_results(\"These are UseSum9 three level cascades\", \"Add.S4\", make_s4_questions())\n",
        "print_question_results(\"These are UseSum9 four level cascades\", \"Add.S5\", make_s5_questions())\n",
        "print_question_results(\"These questions focus on different answer digits\", \"Add.SN\", make_sn_questions())\n",
        "\n",
        "exp0_output.add_row([\"OVERALL\", sum_num_questions, \"\", \"\", sum_total_mean_loss])\n",
        "\n",
        "print_config()\n",
        "print()\n",
        "print(exp0_output.get_formatted_string(out_format=cfg.table_out_format))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 10A: Set Up \"Quanta\" evaluations\n",
        "\n",
        "Define tools to evaluate quanta"
      ],
      "metadata": {
        "id": "fPH-deQUIOGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZXEfGBMLPFW"
      },
      "outputs": [],
      "source": [
        "# Compare each digit in the answer. Returns a A45 pattern where each digit means an incorrect answer digit\n",
        "def get_answer_impact(q, answer_str):\n",
        "\n",
        "  a_str = tokens_to_string(q[-(cfg.n_digits+1):])\n",
        "\n",
        "  impact_str = \"\"\n",
        "  for i in range(cfg.n_digits+1):\n",
        "    impact_str += \"\" if answer_str[i] == a_str[i] else str(cfg.n_digits-i)\n",
        "\n",
        "  if impact_str == \"\":\n",
        "    return \"\"\n",
        "\n",
        "  return \"A\" + impact_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xiOHRfGKW-W"
      },
      "outputs": [],
      "source": [
        "# Analyse the question and return the use case as BA, MC, SimpleUS9 or CascadeUS9\n",
        "def get_question_complexity(q):\n",
        "  qa = utils.to_numpy(q)\n",
        "  qn = qa[:2*cfg.n_digits+2]\n",
        "\n",
        "  # Locate the MC and MS digits (if any)\n",
        "  mc = torch.zeros( cfg.n_digits).to(torch.int64)\n",
        "  ms = torch.zeros( cfg.n_digits).to(torch.int64)\n",
        "  for dn in range(cfg.n_digits):\n",
        "    if qn[dn] + qn[dn + cfg.n_digits + 1] == 9:\n",
        "      ms[cfg.n_digits-1-dn] = 1\n",
        "    if qn[dn] + qn[dn + cfg.n_digits +1] > 9:\n",
        "      mc[cfg.n_digits-1-dn] = 1\n",
        "\n",
        "  # Calculate the use case of a question\n",
        "  if torch.sum(mc) == 0:\n",
        "    return \"S0\"\n",
        "\n",
        "  if torch.sum(ms) == 0:\n",
        "    return \"S1\"\n",
        "\n",
        "  for dn in range(cfg.n_digits-3):\n",
        "    if mc[dn] == 1 and ms[dn+1] == 1 and ms[dn+2] == 1 and ms[dn+3] == 1:\n",
        "      return \"S4\" # MC cascades 3 or more digits\n",
        "\n",
        "  for dn in range(cfg.n_digits-2):\n",
        "    if mc[dn] == 1 and ms[dn+1] == 1 and ms[dn+2] == 1:\n",
        "      return \"S3\" # MC cascades 2 or more digits\n",
        "\n",
        "  for dn in range(cfg.n_digits-1):\n",
        "    if mc[dn] == 1 and ms[dn+1] == 1:\n",
        "      return \"S2\" # Simple US 9\n",
        "\n",
        "  return \"S1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFzN_OxmKcEx"
      },
      "outputs": [],
      "source": [
        "# Test that the get_question_complexity code works as expected\n",
        "def unit_test_get_question_complexity_core(correct_case, questions):\n",
        "  num_questions = questions.shape[0]\n",
        "  print( correct_case, \"#Questions=\", num_questions)\n",
        "  for i in range(num_questions):\n",
        "    question_case = get_question_complexity(questions[i])\n",
        "    if question_case != correct_case:\n",
        "      print( \"Case mismatch:\", correct_case, question_case, questions[i])\n",
        "\n",
        "def unit_test_get_question_complexity():\n",
        "  unit_test_get_question_complexity_core( \"S0\", make_s0_questions())\n",
        "  unit_test_get_question_complexity_core( \"S1\", make_s1_questions())\n",
        "  unit_test_get_question_complexity_core( \"S2\", make_s2_questions())\n",
        "  unit_test_get_question_complexity_core( \"S3\", make_s3_questions())\n",
        "  unit_test_get_question_complexity_core( \"S4\", make_s4_questions())\n",
        "  unit_test_get_question_complexity_core( \"S4\", make_s5_questions())\n",
        "\n",
        "unit_test_get_question_complexity()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyK7QeUjLLFm"
      },
      "source": [
        "#Part 10B: Set Up \"Quanta\" result lists\n",
        "Define tools to count failures by quanta / metrics. Use prefix \"q_\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def increment_dictionary_case_count(dictionary, the_case):\n",
        "  if the_case in dictionary:\n",
        "    # If the key is already in the dictionary, increment its count\n",
        "    dictionary[the_case] += 1\n",
        "  else:\n",
        "    # If the key is not in the dictionary, add it with a count of 1\n",
        "    dictionary[the_case] = 1"
      ],
      "metadata": {
        "id": "2qeNNG1wI1Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Q_Config():\n",
        "  # Build up a list of questions by case (e.g. Add.S0, Add.S1, Sub.M0, Sub.NG, etc)\n",
        "  question_complexity_counts = {}\n",
        "  # Build up a count of question failure cases (e.g. Add.S0, Add.S1, Sub.M0, Sub.NG, etc)\n",
        "  question_complexity_fails = {}\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.question_complexity_counts = {}\n",
        "    self.question_complexity_fails = {}\n",
        "\n",
        "\n",
        "  def add_questions_complexity_count(self, questions):\n",
        "    for i in range(questions.shape[0]):\n",
        "      q_case = get_question_complexity(questions[i])\n",
        "      increment_dictionary_case_count(self.question_complexity_counts, q_case)\n",
        "\n",
        "\n",
        "  def add_question_complexity_fail(self, the_case):\n",
        "    increment_dictionary_case_count(self.question_complexity_fails, the_case)\n",
        "\n",
        "\n",
        "\n",
        "qcfg = Q_Config()\n",
        "qcfg.reset()"
      ],
      "metadata": {
        "id": "i3o1tlSKI8EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liT_UbPOLRhO"
      },
      "outputs": [],
      "source": [
        "def q_total_complexity_fails():\n",
        "  answer = 0\n",
        "  for _, value in qcfg.question_complexity_fails.items():\n",
        "    answer += value\n",
        "  return answer\n",
        "\n",
        "\n",
        "def q_get_complexity_fails():\n",
        "  results = \"\"\n",
        "\n",
        "  if len(qcfg.question_complexity_fails) > 0:\n",
        "    sorted_fails = dict(sorted(qcfg.question_complexity_fails.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    for key, value in sorted_fails.items():\n",
        "      percent = round(100 * value / qcfg.question_complexity_counts[key])\n",
        "      results += \"%\" + key + \"=\" + str(percent)+ \" \"\n",
        "\n",
        "  return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmsGWUbILYin"
      },
      "source": [
        "# Part 12: Ablate ALL Heads in EACH token position. What is the impact on Loss?\n",
        "\n",
        "Here we ablate all heads in each token position (overriding the model memory aka residual stream) and see if loss increases. If loss increases the token position is used by the algorithm. Unused token positions can be excluded from further analysis. Use \"C_\" prefix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def quanta_row(the_layer, the_head):\n",
        "  return the_layer * (cfg.n_heads+1) + the_head\n",
        "\n",
        "\n",
        "def quanta_rows():\n",
        "  return (cfg.n_heads + 1) * cfg.n_layers\n",
        "\n",
        "\n",
        "def get_quanta_row_heading(i):\n",
        "  head = i % (cfg.n_heads + 1)\n",
        "  layer = i // (cfg.n_heads + 1)\n",
        "  return \"L\" + str(layer) + (\"H\" + str(head) if head < cfg.n_heads else \"MLP\")"
      ],
      "metadata": {
        "id": "bVB-RGXshp3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx7LwECBLajQ"
      },
      "outputs": [],
      "source": [
        "class C_Config():\n",
        "  output = PrettyTable()\n",
        "  threshold : int = 0.01\n",
        "\n",
        "  useful_positions = []  # sparce ordered list of useful token positions e.g. 0,1,8,9,10,11\n",
        "  useful_rows = []  # sparce ordered list of useful quanta_rows e.g. 0,1,2,3,4,7\n",
        "\n",
        "  curr_position : int = 0   # zero-based token position to ablate\n",
        "\n",
        "\n",
        "  # Add a token position that we know is used in calculations\n",
        "  def add_useful_position(self, position):\n",
        "    if not (position in self.useful_positions):\n",
        "      self.useful_positions += [position]\n",
        "\n",
        "\n",
        "  # Add a quanta row that we know is used in calculations\n",
        "  def add_useful_row(self, row):\n",
        "    if not (row in self.useful_rows):\n",
        "      self.useful_rows += [row]\n",
        "\n",
        "\n",
        "ccfg = C_Config()\n",
        "ccfg.output.field_names = [\"Position\", \"Fails\", \"% Fails by Complexity\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ig1IHJQM8tw"
      },
      "outputs": [],
      "source": [
        "def q_predict_questions(questions, the_hook):\n",
        "\n",
        "  model.reset_hooks()\n",
        "  model.set_use_attn_result(True)\n",
        "\n",
        "  all_logits = model.run_with_hooks(questions.cuda(), return_type=\"logits\", fwd_hooks=the_hook)\n",
        "  all_losses_raw, all_max_prob_tokens = logits_to_tokens_loss(all_logits, questions.cuda())\n",
        "\n",
        "  qcfg.reset()\n",
        "  qcfg.add_questions_complexity_count(questions)\n",
        "\n",
        "  for question_num in range(questions.shape[0]):\n",
        "    q = questions[question_num]\n",
        "\n",
        "    the_loss_mean = utils.to_numpy(loss_fn(all_losses_raw[question_num]).mean())\n",
        "\n",
        "    # Only show the question if the loss exceeds the threshold (because of the ablated token position)\n",
        "    if the_loss_mean > ccfg.threshold:\n",
        "      answer_str = tokens_to_string(all_max_prob_tokens[question_num])\n",
        "\n",
        "      # Only count the question if the model got the question wrong\n",
        "      impact_str = get_answer_impact( q, answer_str )\n",
        "      if 'A' in impact_str:\n",
        "        the_complexity = get_question_complexity(q)\n",
        "\n",
        "        qcfg.add_question_complexity_fail(the_complexity)\n",
        "\n",
        "        if verbose:\n",
        "          print(tokens_to_string(q), \"ModelAnswer:\", answer_str, \"Impact:\", impact_str, \"Complexity:\", the_complexity )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGL57MRBLdUh"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "\n",
        "\n",
        "def c_set_resid_post_hook(value, hook):\n",
        "  global ccfg\n",
        "\n",
        "  #print( \"In hook\", l_hook_resid_post_name[ccfg.layer], ccfg.ablate, ccfg.curr_position, value.shape) # Get [64, 18, 510] = cfg.batch_size, num_tokens, d_model\n",
        "\n",
        "  # Copy the mean resid post values in position N to all the batch questions\n",
        "  value[:,ccfg.curr_position,:] = mean_resid_post[0,ccfg.curr_position,:].clone()\n",
        "\n",
        "\n",
        "num_questions = 0\n",
        "if cfg.n_digits >= 5 :\n",
        "  c_fwd_hooks = [(l_hook_resid_post_name[0], c_set_resid_post_hook)] if cfg.n_layers == 1 else [(l_hook_resid_post_name[0], c_set_resid_post_hook),(l_hook_resid_post_name[1], c_set_resid_post_hook)]\n",
        "\n",
        "  num_questions = varied_questions.shape[0]\n",
        "\n",
        "  for ccfg.curr_position in range(cfg.n_ctx):\n",
        "    q_predict_questions(varied_questions, c_fwd_hooks)\n",
        "\n",
        "    num_fails = q_total_complexity_fails()\n",
        "    perc_fails = 0\n",
        "    if num_fails > 0:\n",
        "      perc_fails = round(100 * num_fails / num_questions)\n",
        "\n",
        "      ccfg.add_useful_position(ccfg.curr_position)\n",
        "\n",
        "    ccfg.output.add_row([str(ccfg.curr_position), str(perc_fails)+\"%\", q_get_complexity_fails()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpRp5YMmLe1y"
      },
      "outputs": [],
      "source": [
        "print_config()\n",
        "print(\"num_questions=\", num_questions, \"min_useful_position=\", min(ccfg.useful_positions), \"max_useful_position=\", max(ccfg.useful_positions) )\n",
        "print()\n",
        "\n",
        "print(ccfg.output.get_formatted_string(out_format=cfg.table_out_format))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904WBkTOLg_5"
      },
      "source": [
        "# Part 13: Setup: Useful node (cell) matrix\n",
        "\n",
        "Uses \"u_\" prefix."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UsefulCell():\n",
        "  # Position.Layer.Head of the cell\n",
        "  position: int = -1  # token-position. Zero to cfg.n_ctx - 1\n",
        "  layer: int = -1\n",
        "  head: int = -1\n",
        "\n",
        "  # Tags related to the cell of form \"MajorVersion.MinorVersion\"\n",
        "  tags = []\n",
        "\n",
        "\n",
        "  # Is this cell an attention head? If not, it must be an MLP layer\n",
        "  def is_head(self):\n",
        "    return self.head != cfg.n_heads\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.position = -1\n",
        "    self.layer = -1\n",
        "    self.head = -1\n",
        "    self.tags = []\n",
        "\n",
        "\n",
        "  # Remove some/all tafs from this cell\n",
        "  def reset_tags(self, major_version):\n",
        "    if filter == \"\":\n",
        "      self.tags = []\n",
        "    else:\n",
        "      self.tags = [s for s in self.tags if not s.startswith(major_version)]\n",
        "\n",
        "\n",
        "  # Row in a table that this cell is drawn\n",
        "  def cell_row(self):\n",
        "    return quanta_row(self.layer, self.head)\n",
        "\n",
        "\n",
        "  # Add a tag to this cell (if not already present)\n",
        "  def add_tag(self, tag):\n",
        "    if tag != \"\" and (not (tag in self.tags)):\n",
        "      self.tags += [tag]\n",
        "\n",
        "\n",
        "  # Return tags with the matching major\n",
        "  def filter_tags(self, major_version):\n",
        "    assert major_version != \"\"\n",
        "\n",
        "    # Filter strings that start with the given major version\n",
        "    filtered_strings = [s for s in self.tags if s.startswith(major_version)]\n",
        "\n",
        "    # Extract minor versions\n",
        "    minor_versions = [s.split('.')[1] for s in filtered_strings]\n",
        "\n",
        "    return minor_versions\n",
        "\n",
        "\n",
        "  # Return minimum tag with the matching major and minor versions\n",
        "  def min_tag_suffix(self, major_version, minor_version, show_plus = False):\n",
        "    suffixes = self.filter_tags(major_version)\n",
        "\n",
        "    if minor_version != \"\":\n",
        "      suffixes = [s for s in suffixes if s.startswith(minor_version)]\n",
        "\n",
        "    answer = min(suffixes) if suffixes else \"\"\n",
        "\n",
        "    if show_plus and len(suffixes) > 1:\n",
        "      answer += \"+\"\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "  # Return the only tag with the matching major_version\n",
        "  def only_tag(self, major_version):\n",
        "    assert major_version != \"\"\n",
        "\n",
        "    filtered_strings = [s for s in self.tags if s.startswith(major_version)]\n",
        "\n",
        "    num_strings = len(filtered_strings)\n",
        "    if num_strings > 1:\n",
        "      print(\"only_tag logic failure\", major_version, num_strings, filtered_strings)\n",
        "      assert False\n",
        "\n",
        "    return filtered_strings[0].split('.')[1] if num_strings == 1 else \"\"\n",
        "\n",
        "\n",
        "  def to_dict(self):\n",
        "    return {\n",
        "      \"position\": self.position,\n",
        "      \"layer\": self.layer,\n",
        "      \"head\": self.head,\n",
        "      \"tags\": self.tags\n",
        "    }\n",
        "\n",
        "\n",
        "  def __init__(self, position, layer, head, tags):\n",
        "    self.position = position\n",
        "    self.layer = layer\n",
        "    self.head = head\n",
        "    self.tags = tags"
      ],
      "metadata": {
        "id": "YrhP2AjSSNee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ar09TTKRSpJM"
      },
      "outputs": [],
      "source": [
        "class U_Config():\n",
        "  num_heads : int\n",
        "  num_mlps : int\n",
        "\n",
        "  useful_cells = []\n",
        "\n",
        "  curr_position : int\n",
        "  curr_layer : int\n",
        "  curr_head : int\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.num_heads = 0\n",
        "    self.num_mlps = 0\n",
        "    self.useful_cells = []\n",
        "\n",
        "    self.curr_position = 0\n",
        "    self.curr_layer = 0\n",
        "    self.curr_head = 0\n",
        "\n",
        "\n",
        "  def reset_tags(self, major_version = \"\"):\n",
        "    for cell in self.useful_cells:\n",
        "      cell.reset_tags(major_version)\n",
        "\n",
        "\n",
        "  def get_cell( self, the_row, the_position ):\n",
        "    for cell in self.useful_cells:\n",
        "      if cell.position == the_position and cell.cell_row() == the_row:\n",
        "        return cell\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "  def add_cell_tag( self, tag ):\n",
        "    assert self.curr_position  >= 0\n",
        "    assert self.curr_layer >= 0\n",
        "    assert self.curr_head >= 0\n",
        "    assert self.curr_position < cfg.n_ctx\n",
        "    assert self.curr_layer < cfg.n_layers\n",
        "    assert self.curr_head <= cfg.n_heads\n",
        "\n",
        "    the_row = quanta_row(self.curr_layer, self.curr_head)\n",
        "    assert the_row >= 0\n",
        "\n",
        "    the_cell = self.get_cell(the_row, self.curr_position )\n",
        "    if the_cell == None:\n",
        "\n",
        "      the_cell = UsefulCell(self.curr_position , self.curr_layer, self.curr_head, [])\n",
        "\n",
        "      self.useful_cells += [the_cell]\n",
        "      if the_cell.is_head():\n",
        "        self.num_heads += 1\n",
        "      else:\n",
        "        self.num_mlps += 1\n",
        "\n",
        "    the_cell.add_tag(tag)\n",
        "\n",
        "\n",
        "ucfg = U_Config()\n",
        "ucfg.reset()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def u_predict_questions(questions, the_hook):\n",
        "\n",
        "  model.reset_hooks()\n",
        "  model.set_use_attn_result(True)\n",
        "\n",
        "  all_logits = model.run_with_hooks(questions.cuda(), return_type=\"logits\", fwd_hooks=the_hook)\n",
        "  all_losses_raw, all_max_prob_tokens = logits_to_tokens_loss(all_logits, questions.cuda())\n",
        "\n",
        "  num_fails = 0\n",
        "  for question_num in range(questions.shape[0]):\n",
        "    q = questions[question_num]\n",
        "\n",
        "    the_loss_mean = utils.to_numpy(loss_fn(all_losses_raw[question_num]).mean())\n",
        "\n",
        "    # Only show the question if the loss exceeds the threshold (because of the ablated token position)\n",
        "    if the_loss_mean > ccfg.threshold:\n",
        "      answer_str = tokens_to_string(all_max_prob_tokens[question_num])\n",
        "\n",
        "      impact_str = get_answer_impact( q, answer_str )\n",
        "      # Only count the question if the model got the question wrong\n",
        "      if 'A' in impact_str:\n",
        "        num_fails += 1\n",
        "        the_complexity = get_question_complexity(q)\n",
        "\n",
        "        # Add question complexity quanta\n",
        "        ucfg.add_cell_tag( addition_major_tag + \".\"+ the_complexity )\n",
        "\n",
        "        # Add answer digit impact quanta\n",
        "        ucfg.add_cell_tag( impact_major_tag + \".\"+ impact_str )\n",
        "\n",
        "        if verbose :\n",
        "          print(tokens_to_string(q), \"U: ModelAnswer:\", answer_str, \"Complexity:\", the_complexity, \"Impact:\", impact_str, \"Loss:\", the_loss_mean )\n",
        "\n",
        "  if num_fails > 0:\n",
        "    # Add percentage failure quanta\n",
        "    perc = int( 100.0 * num_fails / len(questions))\n",
        "    perc_tag = perc_major_tag + '.' + str(perc)\n",
        "    ucfg.add_cell_tag( perc_tag)\n",
        "\n",
        "    ccfg.add_useful_row(quanta_row(ucfg.curr_layer, ucfg.curr_head))"
      ],
      "metadata": {
        "id": "maeJHlipQ3Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOxNc9SAMGRH"
      },
      "outputs": [],
      "source": [
        "def m_mlp_hook_post(value, hook):\n",
        "  #print( \"In m_mlp_hook_post\", value.shape) # Get [1, 18, 2040] = ???, cfg.n_ctx, cfg.d_mlp\n",
        "\n",
        "  # Mean ablate. Copy the mean resid post values in position N to the MLP\n",
        "  value[:,ucfg.curr_position,:] =  mean_mlp_hook_post[:,ucfg.curr_position,:].clone()\n",
        "\n",
        "\n",
        "# Ablating the MLP in each layer in each position and seeing if the loss increases shows which head+layer+MLP are used by the algorithm.\n",
        "def u_mlp_perform_all(questions):\n",
        "  ucfg.curr_head = cfg.n_heads\n",
        "  for ucfg.curr_position in ccfg.useful_positions:\n",
        "    for ucfg.curr_layer in range(cfg.n_layers):\n",
        "      the_hook = [(l_mlp_hook_post_name[ucfg.curr_layer], m_mlp_hook_post)]\n",
        "      u_predict_questions(questions, the_hook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2EnisO6MMGQ"
      },
      "outputs": [],
      "source": [
        "def h_set_attn_hook_z(value, hook):\n",
        "  # print( \"In h_set_attn_hook_z\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "\n",
        "  # Mean ablate. Copy the mean resid post values in position N to all the batch questions\n",
        "  value[:,ucfg.curr_position,ucfg.curr_head,:] = mean_attn_z[:,ucfg.curr_position,ucfg.curr_head,:].clone()\n",
        "\n",
        "\n",
        "def u_head_perform_all(questions):\n",
        "  for ucfg.curr_position in ccfg.useful_positions:\n",
        "    for ucfg.curr_layer in range(cfg.n_layers):\n",
        "      for ucfg.curr_head in range(cfg.n_heads):\n",
        "        the_hook = [(l_attn_hook_z_name[ucfg.curr_layer], h_set_attn_hook_z)]\n",
        "        u_predict_questions(questions, the_hook)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def h_null_attn_z_hook(value, hook):\n",
        "  global ucfg\n",
        "\n",
        "  #print(\"In h_null_attn_z_hook\", value.shape)  # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "\n",
        "\n",
        "def u_calculate_attention_tags(questions):\n",
        "  ucfg.reset_tags(attention_major_tag)\n",
        "\n",
        "  logits, cache = model.run_with_cache(questions)\n",
        "\n",
        "  all_attention_weights = []\n",
        "  for layer in range(cfg.n_layers):\n",
        "    attention_weights = cache[\"pattern\", layer, \"attn\"]\n",
        "    #print(attention_weights.shape) # 512, 4, 22, 22 = cfg.batch_size, cfg.n_heads, cfg.n_ctx, cfg.n_ctx\n",
        "\n",
        "    average_attention_weights = attention_weights.mean(dim=0)\n",
        "    #print(average_attention_weights.shape) # 4, 22, 22 = cfg.n_heads, cfg.n_ctx, cfg.n_ctx\n",
        "\n",
        "    all_attention_weights += [average_attention_weights]\n",
        "\n",
        "\n",
        "  for cell in ucfg.useful_cells:\n",
        "    if cell.is_head():\n",
        "      # Get attention weights for this token in this head\n",
        "      layer_weights = all_attention_weights[cell.layer]\n",
        "      weights = layer_weights[cell.head, cell.position, :]\n",
        "\n",
        "      top_tokens = torch.topk(weights, 4)\n",
        "      total_attention = weights.sum()\n",
        "      attention_percentage = top_tokens.values / total_attention * 100\n",
        "\n",
        "      # Add up to 4 tags with percs per head\n",
        "      for idx, token_idx in enumerate(top_tokens.indices):\n",
        "        perc = attention_percentage[idx]\n",
        "        if perc >= 1.0:\n",
        "          ucfg.curr_position = cell.position\n",
        "          ucfg.curr_layer = cell.layer\n",
        "          ucfg.curr_head = cell.head\n",
        "          ucfg.add_cell_tag( f\"{attention_major_tag}.{token_idx}={perc:.0f}\" )\n"
      ],
      "metadata": {
        "id": "J4XG_OJXb8dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Uluv96KMQJS"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "ucfg.reset()\n",
        "u_mlp_perform_all(varied_questions)\n",
        "u_head_perform_all(varied_questions)\n",
        "u_calculate_attention_tags(varied_questions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Part 15: Set up: Draw quanta map"
      ],
      "metadata": {
        "id": "-u5w87NMP6lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a colormap for use with graphing\n",
        "def create_custom_colormap():\n",
        "    colors = [\"green\", \"yellow\"]\n",
        "    return mcolors.LinearSegmentedColormap.from_list(\"custom_colormap\", colors)\n",
        "\n",
        "\n",
        "# Blend the color with white to make it paler\n",
        "def pale_color(color, factor=0.5):\n",
        "    color_array = np.array(color)\n",
        "    white = np.array([1, 1, 1, 1])\n",
        "    return white * factor + color_array * (1 - factor)"
      ],
      "metadata": {
        "id": "rP7luaRMiPio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class quanta_result:\n",
        "  model_row : int = 0\n",
        "  model_col : int = 0\n",
        "  cell_text : str = \"\"\n",
        "  color_index :int = -1\n",
        "\n",
        "  def __init__(self, model_row, model_col, cell_text, color_index):\n",
        "    self.model_row = model_row\n",
        "    self.model_col = model_col\n",
        "    self.cell_text = cell_text\n",
        "    self.color_index = color_index\n",
        "\n",
        "\n",
        "def calc_quanta_results( major_version, minor_version, get_cell_details, shades ):\n",
        "\n",
        "  quanta_results = []\n",
        "\n",
        "  for raw_row in ccfg.useful_rows:\n",
        "    for raw_col in ccfg.useful_positions:\n",
        "      cell_text, color_index = get_cell_details(raw_row, raw_col, major_version, minor_version, shades)\n",
        "      if cell_text != \"\" :\n",
        "        quanta_results +=[quanta_result(model_row=raw_row, model_col=raw_col, cell_text=cell_text, color_index=color_index )]\n",
        "\n",
        "  return quanta_results\n",
        "\n",
        "\n",
        "def find_quanta_result_by_row_col(row, col, quanta_results):\n",
        "    for result in quanta_results:\n",
        "        if result.model_row == row and result.model_col == col:\n",
        "            return result\n",
        "    return None"
      ],
      "metadata": {
        "id": "9S5ghKOhHE4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert token positions to D5, .., D0, -, D'5, .., D'0, =, -, A6, .., A0\n",
        "def token_position_to_name( position ):\n",
        "  if position < cfg.n_digits:\n",
        "    return \"D\" + str(cfg.n_digits-position-1)\n",
        "\n",
        "  if position == cfg.n_digits:\n",
        "    return \"+\"\n",
        "\n",
        "  if position <= 2 * cfg.n_digits:\n",
        "    return \"D'\" + str(2*cfg.n_digits-position)\n",
        "\n",
        "  if position == 2 * cfg.n_digits + 1:\n",
        "    return \"=\"\n",
        "\n",
        "  return \"A\" + str(3*cfg.n_digits-position+2)\n",
        "\n",
        "\n",
        "def unit_test_token_position_to_name():\n",
        "  for i in range (cfg.n_ctx):\n",
        "    print(token_position_to_name(i))\n",
        "\n",
        "\n",
        "#unit_test_token_position_to_name()"
      ],
      "metadata": {
        "id": "4Ebja6pjcAPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_quanta_add_patch(ax, j, row, cell_color):\n",
        "  ax.add_patch(plt.Rectangle((j, row), 1, 1, fill=True, color=cell_color))\n",
        "\n",
        "\n",
        "def show_quanta_map( title, custom_cmap, shades, major_version, minor_version, get_cell_details, base_fontsize = 10, max_width = 10):\n",
        "\n",
        "  quanta_results = calc_quanta_results(major_version, minor_version, get_cell_details, shades)\n",
        "\n",
        "  distinct_rows = set()\n",
        "  distinct_cols = set()\n",
        "\n",
        "  for result in quanta_results:\n",
        "      distinct_rows.add(result.model_row)\n",
        "      distinct_cols.add(result.model_col)\n",
        "\n",
        "  distinct_rows = sorted(distinct_rows)\n",
        "  distinct_cols = sorted(distinct_cols)\n",
        "\n",
        "  print_config()\n",
        "  print()\n",
        "\n",
        "  # Create figure and axes\n",
        "  fig1, ax1 = plt.subplots(figsize=(2*len(distinct_cols)/3, 2*len(distinct_rows)/3))  # Adjust the figure size as needed\n",
        "\n",
        "  # Ensure cells are square\n",
        "  ax1.set_aspect('equal', adjustable='box')\n",
        "  ax1.yaxis.set_tick_params(labelleft=True, labelright=False)\n",
        "\n",
        "  colors = [pale_color(custom_cmap(i/shades)) for i in range(shades)]\n",
        "  vertical_labels = []\n",
        "  horizontal_labels = []\n",
        "  wrapper = textwrap.TextWrapper(width=max_width)\n",
        "\n",
        "\n",
        "  show_row = len(distinct_rows)-1\n",
        "  for raw_row in distinct_rows:\n",
        "    vertical_labels += [get_quanta_row_heading(raw_row)]\n",
        "\n",
        "    show_col = 0\n",
        "    for raw_col in distinct_cols:\n",
        "      cell_color = 'lightgrey'  # Color for empty cells\n",
        "\n",
        "      if show_row == 0:\n",
        "        horizontal_labels += [token_position_to_name(raw_col)]\n",
        "\n",
        "      result = find_quanta_result_by_row_col(raw_row, raw_col, quanta_results)\n",
        "      if result != None:\n",
        "        cell_color = colors[result.color_index] if result.color_index >= 0 else 'lightgrey'\n",
        "        the_fontsize = base_fontsize if len(result.cell_text) < 4 else base_fontsize-1 if len(result.cell_text) < 5 else base_fontsize-2\n",
        "        wrapped_text = wrapper.fill(text=result.cell_text)\n",
        "        ax1.text(show_col + 0.5, show_row + 0.5, wrapped_text, ha='center', va='center', color='black', fontsize=the_fontsize)\n",
        "\n",
        "      show_quanta_add_patch(ax1, show_col, show_row, cell_color)\n",
        "      show_col += 1\n",
        "\n",
        "    show_row -= 1\n",
        "\n",
        "\n",
        "  # Configure x axis\n",
        "  ax1.set_xlim(0, len(horizontal_labels))\n",
        "  ax1.set_xticks(np.arange(0.5, len(horizontal_labels), 1))\n",
        "  ax1.set_xticklabels(horizontal_labels)\n",
        "  ax1.xaxis.tick_top()\n",
        "  ax1.xaxis.set_label_position('top')\n",
        "  ax1.tick_params(axis='x', length=0)\n",
        "  for label in ax1.get_xticklabels():\n",
        "    label.set_fontsize(9)\n",
        "\n",
        "  # Configure y axis\n",
        "  vertical_labels = vertical_labels[::-1] # Reverse the order\n",
        "  ax1.set_ylim(0, len(vertical_labels))\n",
        "  ax1.set_yticks(np.arange(0.5, len(vertical_labels), 1))\n",
        "  ax1.set_yticklabels(vertical_labels)\n",
        "  ax1.tick_params(axis='y', length=0)\n",
        "  for label in ax1.get_yticklabels():\n",
        "    label.set_horizontalalignment('left')\n",
        "    label.set_position((-0.1, 0))  # Adjust the horizontal position\n",
        "    #label.set_fontsize(9)\n",
        "\n",
        "  fulltitle = op_prefix + ': ' + title + ' (d{}_l{}_h{})'.format(cfg.n_digits, cfg.n_layers, cfg.n_heads)\n",
        "\n",
        "  if cfg.save_graph_to_file:\n",
        "    print(\"Saving quanta map:\", fulltitle)\n",
        "    filename = fulltitle.replace( ' ', '_').replace( '-', '_').replace( ':', '_')\n",
        "    plt.savefig(filename+\".pdf\", bbox_inches='tight', pad_inches=0)\n",
        "    #plt.savefig(filename+\".svg\")\n",
        "  else:\n",
        "    ax1.set_title(fulltitle + ' ({} nodes)'.format(len(quanta_results)))\n",
        "\n",
        "  # Show plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "6XcFDCs9P8Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpkyhHRoMOSw"
      },
      "source": [
        "# Part 16A: Results: Show failure percentage quanta map\n",
        "\n",
        "Show the percentage failure rate (incorrect prediction) when individual Attention Heads and MLPs are ablated."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cell in ucfg.useful_cells:\n",
        "  print( cell.position, cell.layer, cell.head, cell.tags)"
      ],
      "metadata": {
        "id": "EywGsPchglMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ28dx5YLs0P"
      },
      "outputs": [],
      "source": [
        "def get_quanta_fail_percs( row, col, major_version, minor_version, shades):\n",
        "  cell_text = \"\"\n",
        "  color_index = 0\n",
        "\n",
        "  cell = ucfg.get_cell( row, col )\n",
        "  if cell != None:\n",
        "    cell_text = cell.only_tag( major_version )\n",
        "    value = int(cell_text) if cell_text != \"\" else 0\n",
        "\n",
        "    if value == 100 and ccfg.num_col_headings() > 5:\n",
        "      value = 99 # Avoid overlapping figures in the matrix.\n",
        "    color_index = value // shades\n",
        "    cell_text = (str(value) if value > 0 else \"<1\") + \"%\"\n",
        "\n",
        "  return cell_text, color_index\n",
        "\n",
        "\n",
        "show_quanta_map( varied_major_tag, plt.cm.winter, 10, perc_major_tag, \"\", get_quanta_fail_percs, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 16B: Result: Show attention quanta map\n",
        "\n",
        "Show attention quanta of useful cells"
      ],
      "metadata": {
        "id": "M5ZxVECzcEkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_attention_perc = 1 # Only show input tokens with >= 1% of attention\n",
        "\n",
        "\n",
        "# Only maps attention heads, not MLP layers\n",
        "def get_quanta_attention_tag(row, col, major_version, minor_version, shades):\n",
        "  cell_text = \"\"\n",
        "  color_index = 0\n",
        "\n",
        "  if not \"MLP\" in get_quanta_row_heading(row):\n",
        "    cell = ucfg.get_cell( row, col )\n",
        "    if cell != None:\n",
        "      sum_perc = 0\n",
        "      for minor_version in cell.filter_tags( major_version ):\n",
        "        cell_parts = minor_version.split(\"=\")\n",
        "        token_pos = int(cell_parts[0])\n",
        "        the_perc = int(cell_parts[1])\n",
        "        if the_perc >= min_attention_perc:\n",
        "          cell_text += token_position_to_name(token_pos) + \" \"\n",
        "          sum_perc += the_perc\n",
        "\n",
        "      cell_text = cell_text.rstrip(\" \")\n",
        "      color_index = 10 - sum_perc // 10    # Want >90% => Dark-Green, and <10% => Yellow\n",
        "\n",
        "  return cell_text, color_index\n",
        "\n",
        "\n",
        "# Only maps attention heads, not MLP layers\n",
        "show_quanta_map( \"Attention per node\", create_custom_colormap(), 10, attention_major_tag, \"\", get_quanta_attention_tag, 10, 6)"
      ],
      "metadata": {
        "id": "u-guTU09cILX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 16C - Show question complexity (S*) quanta map\n",
        "Show the \"minimum\" addition purpose of each useful cell by S0 to S4 quanta."
      ],
      "metadata": {
        "id": "BhhTk0tmvmQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_quanta_min_tag(row, col, major_version, minor_version, shades):\n",
        "  cell_text = \"\"\n",
        "  color_index = 0\n",
        "\n",
        "  cell = ucfg.get_cell( row, col )\n",
        "  if cell != None:\n",
        "    cell_text = cell.min_tag_suffix( major_version, minor_version )\n",
        "\n",
        "    if cell_text != \"\" :\n",
        "      color_index = int(cell_text[1]) if len(cell_text) > 1 and cell_text[1].isdigit() else shades-1\n",
        "\n",
        "  return cell_text, color_index\n",
        "\n",
        "\n",
        "show_quanta_map( \"Addition minimum-quanta per node\", create_custom_colormap(), 6, addition_major_tag, \"\", get_quanta_min_tag, 11)"
      ],
      "metadata": {
        "id": "Z-j9vtw3chkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 16D - Show answer impact quanta map\n",
        "\n",
        "Show the purpose of each useful cell by impact on the answer digits A0 to A5."
      ],
      "metadata": {
        "id": "lSxC4S2W7jn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_sequential(digits):\n",
        "    return all(int(digits[i]) + 1 == int(digits[i+1]) for i in range(len(digits) - 1))"
      ],
      "metadata": {
        "id": "Qw8IRPCu7uaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicate_digits(input_string):\n",
        "    seen = set()\n",
        "    result = \"\"\n",
        "    for char in input_string:\n",
        "        if char not in seen:\n",
        "            seen.add(char)\n",
        "            result += char\n",
        "    return result\n",
        "\n",
        "# Unit test\n",
        "# print( remove_duplicate_digits(\"1231231278321\"))"
      ],
      "metadata": {
        "id": "LTbYXirgfjQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_impact_quanta_range( row, col, major_version, minor_version, shades):\n",
        "\n",
        "  cell_text = \"\"\n",
        "  color_index = 0\n",
        "\n",
        "  cell = ucfg.get_cell( row, col )\n",
        "  if cell != None and len(cell.tags) > 0:\n",
        "\n",
        "    cell_texts = cell.filter_tags( major_version )\n",
        "    if len(cell_texts) > 0:\n",
        "\n",
        "      # Check for '-' sign\n",
        "      has_dash = any('-' in s for s in cell_texts)\n",
        "\n",
        "      digits = \"\"\n",
        "      for s in cell_texts:\n",
        "        digits += ''.join(filter(str.isdigit, s))\n",
        "      digits = sorted(remove_duplicate_digits(digits))\n",
        "\n",
        "      if len(digits) >= 3 and is_sequential(digits):\n",
        "        digits = f\"{digits[0]}..{digits[-1]}\"\n",
        "\n",
        "      # Joining numbers with the appropriate prefix\n",
        "      cell_text = (\"A-\" if has_dash else \"A\") + ''.join(digits)\n",
        "\n",
        "      color_index = int(cell_text[1]) if len(cell_text) > 1 and cell_text[1].isdigit() else shades-1\n",
        "\n",
        "  return cell_text, color_index\n",
        "\n",
        "\n",
        "show_quanta_map( \"Answer-digit-impact per node\", create_custom_colormap(), cfg.n_digits+2, impact_major_tag, \"\", get_impact_quanta_range, 11)"
      ],
      "metadata": {
        "id": "STZrKWNRfmAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHSY3blNMe7I"
      },
      "source": [
        "#Part 18: SetUp: Calc and graph PCA decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCiBsiQAMhS_"
      },
      "outputs": [],
      "source": [
        "tn_questions = 100\n",
        "\n",
        "# These are n_digit addition questions where the first test_digits add up from 0 to 8\n",
        "# Randomise the last test_digits-1 digits of both numbers\n",
        "def make_t8_questions(test_digit):\n",
        "    limit = 10 ** test_digit\n",
        "    questions = []\n",
        "    for i in range(tn_questions):\n",
        "        x = random.randint(0, 8)\n",
        "        y = random.randint(0, 8-x)\n",
        "        x = x * limit + random.randint(0, limit-1)\n",
        "        y = y * limit + random.randint(0, limit-1)\n",
        "        questions.append([x, y])\n",
        "    return make_questions(questions)\n",
        "\n",
        "\n",
        "# These are n_digit addition questions where the first test_digits add up to 9\n",
        "# Randomise the last test_digits-1 digits of both numbers\n",
        "def make_t9_questions(test_digit):\n",
        "    limit = 10 ** test_digit\n",
        "    questions = []\n",
        "    for i in range(tn_questions):\n",
        "        x = random.randint(0, 9)\n",
        "        y = 9 - x\n",
        "        x = x * limit + random.randint(0, limit-1)\n",
        "        y = y * limit + random.randint(0, limit-1)\n",
        "        questions.append([x, y])\n",
        "    return make_questions(questions)\n",
        "\n",
        "\n",
        "# These are n_digit addition questions where the first test_digits add up to 10 to 18\n",
        "# Randomise the last test_digits-1 digits of both numbers\n",
        "def make_t10_questions(test_digit):\n",
        "    limit = 10 ** test_digit\n",
        "    questions = []\n",
        "    for i in range(tn_questions):\n",
        "        x = random.randint(1, 9)\n",
        "        y = random.randint(10-x, 9)\n",
        "        x = x * limit + random.randint(0, limit-1)\n",
        "        y = y * limit + random.randint(0, limit-1)\n",
        "        questions.append([x, y])\n",
        "    return make_questions(questions)\n",
        "\n",
        "\n",
        "def make_tricase_questions(test_digit):\n",
        "  q1 = make_t8_questions(test_digit)\n",
        "  q2 = make_t9_questions(test_digit)\n",
        "  q3 = make_t10_questions(test_digit)\n",
        "\n",
        "  questions = torch.vstack((q1, q2, q3))\n",
        "\n",
        "  return questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWCPgoQZMjgc"
      },
      "outputs": [],
      "source": [
        "# Do one Principal Component Analysis\n",
        "def calc_tricase_pca(t_position, t_layer, t_head, t_digit):\n",
        "  global tn_questions\n",
        "\n",
        "  t_questions = make_tricase_questions(t_digit)\n",
        "  #print('Sample t8 question:', t_questions[0].tolist())\n",
        "  #print('Sample t9 question:', t_questions[tn_questions].tolist())\n",
        "  #print('Sample t10 question:', t_questions[2*tn_questions].tolist())\n",
        "\n",
        "  t_logits, t_cache = model.run_with_cache(t_questions)\n",
        "\n",
        "  # Gather attention patterns for all the (randomly chosen) questions\n",
        "  attention_outputs = []\n",
        "  for i in range(len(t_questions)):\n",
        "\n",
        "    # Output of individual heads, without final bias\n",
        "    attention_cache=t_cache[\"result\", t_layer, \"attn\"] # Output of individual heads, without final bias\n",
        "    attention_output=attention_cache[i]  # Shape [n_ctx, n_head, d_model]\n",
        "    attention_outputs.append(attention_output[t_position, t_head, :])\n",
        "\n",
        "  attn_outputs = torch.stack(attention_outputs, dim=0).cpu()\n",
        "\n",
        "  pca = PCA(n_components=6)\n",
        "  pca.fit(attn_outputs)\n",
        "  pca_attn_outputs = pca.transform(attn_outputs)\n",
        "\n",
        "  title = 'P' + str(t_position) + '.L' + str(t_layer) + '.H'+str(t_head) + ', A'+str(t_digit)\n",
        "\n",
        "  return (pca, pca_attn_outputs, title)\n",
        "\n",
        "\n",
        "# Plot one PCA scatter graph\n",
        "def graph_pca(pca, pca_attn_outputs, ax, title):\n",
        "  global tn_questions\n",
        "\n",
        "  ax.scatter(pca_attn_outputs[:tn_questions, 0], pca_attn_outputs[:tn_questions, 1], color='red', label='T8: 0-8') # t8 questions\n",
        "  ax.scatter(pca_attn_outputs[tn_questions:2*tn_questions, 0], pca_attn_outputs[tn_questions:2*tn_questions, 1], color='green', label='T9') # t9 questions\n",
        "  ax.scatter(pca_attn_outputs[2*tn_questions:, 0], pca_attn_outputs[2*tn_questions:, 1], color='blue', label='T10: 10-18') # t10 questionsset\n",
        "\n",
        "  if title != \"\" :\n",
        "    ax.set_title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk2K3y7pMlQr"
      },
      "outputs": [],
      "source": [
        "# Graph the PCA of Sn.Ln.Hn's attention pattern, using T8, T9, T10 questions that differ in the An digit\n",
        "def add_one_pca_subplot(ax, t_position, t_layer, t_head, t_digit):\n",
        "  pca, pca_attn_outputs, title = calc_tricase_pca(t_position, t_layer, t_head, t_digit)\n",
        "  graph_pca( pca, pca_attn_outputs, ax, title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEF7MQqCMngv"
      },
      "outputs": [],
      "source": [
        "def save_plt_to_file( full_title ):\n",
        "  if cfg.save_graph_to_file:\n",
        "    filename = full_title.replace(\" \", \"_\").replace(\",\", \"\").replace(\":\", \"_\")  + '.pdf'\n",
        "    plt.savefig(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbiau9foMp3h"
      },
      "source": [
        "#Part 19: PCA decomposition tri-state results\n",
        "\n",
        "Plot attention heads in the positions 8 to 16 with a clear \"tri-state\" response to (exactly) one An."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ5fS3XNMs8e"
      },
      "outputs": [],
      "source": [
        "if cfg.n_digits == 5 and cfg.n_layers == 2 and use_pca :\n",
        "\n",
        "  # graph all useful early cells\n",
        "  fig, axs = plt.subplots(4, 2)\n",
        "  fig.set_figheight(8)\n",
        "  fig.set_figwidth(5)\n",
        "\n",
        "  # Plot all useful attention heads in the positions 8 to 12 with the clearest An selected\n",
        "  add_one_pca_subplot(axs[0, 0], 8, 0, 1, 2)    # P8.L0.H1 is clear only for A2\n",
        "  add_one_pca_subplot(axs[0, 1], 9, 0, 1, 1)    # P9.L0.H1 is clear only for A1\n",
        "  add_one_pca_subplot(axs[1, 0], 11, 0, 1, 3)   # P11.L0.H1 is clear only for A3\n",
        "  add_one_pca_subplot(axs[1, 1], 11, 0, 2, 4)   # P11.L0.H2 is clear only for A4\n",
        "  add_one_pca_subplot(axs[2, 0], 12, 0, 1, 3)   # P12.L0.H1 is clear only for A3\n",
        "  add_one_pca_subplot(axs[2, 1], 13, 0, 1, 2)   # P13.L0.H1 is clear only for A2\n",
        "  add_one_pca_subplot(axs[3, 0], 14, 0, 1, 1)   # P14.L0.H1 is clear only for A1\n",
        "\n",
        "  lines_labels = [axs[0,0].get_legend_handles_labels()]\n",
        "  lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
        "  # fig.legend(lines, labels, loc='lower center', ncol=4)\n",
        "  # fig.subplots_adjust(bottom=0.2)  # Adjust the bottom spacing\n",
        "\n",
        "  axs[3, 1].legend(lines, labels)\n",
        "  axs[3, 1].axis('off') # Now, to hide the last subplot\n",
        "\n",
        "  plt.tight_layout()\n",
        "  save_plt_to_file('PCA_Trigrams')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3611cpuEFhoW"
      },
      "source": [
        "#Part 19B: PCA decomposition bi-state results\n",
        "\n",
        "Plot attention heads in the positions 8 to 16 with a clear \"bi-state\" response to (exactly) one An."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAT8Z54oMuur"
      },
      "outputs": [],
      "source": [
        "if cfg.n_digits == 5 and cfg.n_layers == 2 and use_pca :\n",
        "\n",
        "  # graph all useful early cells\n",
        "  fig, axs = plt.subplots(1, 2)\n",
        "  fig.set_figheight(2)\n",
        "  fig.set_figwidth(5)\n",
        "\n",
        "  # Plot all useful attention heads in the positions 8 to 12 with the clearest An selected\n",
        "  add_one_pca_subplot(axs[0], 10, 0, 1, 0)   # P10.L0.H1 is clear only for A0\n",
        "  add_one_pca_subplot(axs[1], 15, 0, 1, 0)   # P15.L0.H1 is clear only for A0\n",
        "\n",
        "  lines_labels = [axs[0].get_legend_handles_labels()]\n",
        "  lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
        "  #fig.legend(lines, labels, loc='lower center', ncol=4)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  save_plt_to_file('PCA_Bigrams')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQhbJTFTMwU_"
      },
      "outputs": [],
      "source": [
        "# Do one Principal Component Analysis and graph it\n",
        "def run_one_tricase_pca(t_position, t_layer, t_head, t_digit):\n",
        "\n",
        "  pca, pca_attn_outputs, title = calc_tricase_pca(t_position, t_layer, t_head, t_digit)\n",
        "\n",
        "  # Plot the PCA results\n",
        "  fig, ax = plt.subplots()\n",
        "  graph_pca(pca, pca_attn_outputs, ax, \"\")\n",
        "\n",
        "  full_title = 'PCA of attention: n_digits=' + str(cfg.n_digits) + ', ' + title\n",
        "  plt.title(full_title + ', EVR[0]=' + str(round(pca.explained_variance_ratio_[0],3)) )\n",
        "\n",
        "  plt.tight_layout()\n",
        "  save_plt_to_file(full_title)\n",
        "  plt.show()\n",
        "\n",
        "  print( \"First few principal components explain variance of:\", pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIu3Pr9CMx3l"
      },
      "source": [
        "#Part 19C: PCA decomposition of useful cells with digits 0 to 4\n",
        "\n",
        "Parts 19A and 19B are selective. This part is not. Use it to find (verify) the interesting parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdfpkXmAMzg4"
      },
      "outputs": [],
      "source": [
        "def graph_all_pca_results():\n",
        "\n",
        "  for useful_cell in ucfg.useful_cells:\n",
        "      if useful_cell.is_head():\n",
        "        position = useful_cell.position\n",
        "        layer = useful_cell.layer\n",
        "        head = useful_cell.head\n",
        "        print( \"PCA: position=\", position, \"layer=\", layer, \"head=\", head)\n",
        "\n",
        "        fig, axs = plt.subplots(3, 2)\n",
        "\n",
        "        add_one_pca_subplot(axs[0, 0], position, layer, head, 0)\n",
        "        add_one_pca_subplot(axs[0, 1], position, layer, head, 1)\n",
        "        add_one_pca_subplot(axs[1, 0], position, layer, head, 2)\n",
        "        add_one_pca_subplot(axs[1, 1], position, layer, head, 3)\n",
        "        add_one_pca_subplot(axs[2, 0], position, layer, head, 4)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "if use_pca :\n",
        "  graph_all_pca_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO3kH-aQyM3U"
      },
      "source": [
        "# Part 20: Implement Mathematical framework\n",
        "\n",
        "Demonstrates that the mathematical framework (not the model) can do 1,000,000 additions without error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OauytHdPyRyi"
      },
      "outputs": [],
      "source": [
        "def tri_case(dn,dnd):\n",
        "  s = dn + dnd\n",
        "  if s >= 10:\n",
        "    return 10\n",
        "  if s == 9:\n",
        "    return 9\n",
        "  return 8\n",
        "\n",
        "def tri_add(dn_cx, dm_cy):\n",
        "  if dn_cx == 10 or (dn_cx == 9 and dm_cy == 10):\n",
        "    return 10\n",
        "  if dn_cx == 8 and dm_cy == 10:\n",
        "    return 9\n",
        "  return 8\n",
        "\n",
        "def addition_psuedo_code( d4, d3, d2, d1, d0, d4d, d3d, d2d, d1d, d0d ):\n",
        "  # V2.C | TriCase(D2, D2â€™) | P8.L0.H1 and P8.L0.MLP\n",
        "  v2_c = tri_case(d2, d2d)\n",
        "\n",
        "  # V1.C | TriCase(D1, D1') | P9.L0.H1 and P9.L0.MLP\n",
        "  v1_c = tri_case(d1, d1d)\n",
        "\n",
        "  # V1.C2 | TriAdd(V1.C, TriCase(D0, D0â€™)) | P10.L0.H1 and P10.L0.MLP\n",
        "  v1_c2 =  tri_add( v1_c, tri_case(d0, d0d) )\n",
        "\n",
        "  # V3.C4 | TriAdd(TriCase(D3, D3â€™), TriAdd(V2.C,V1.C2)) | P11.L0.H1\n",
        "  v3_c4 = tri_add( tri_case(d3, d3d), tri_add(v2_c,v1_c2) )\n",
        "\n",
        "  # V4.C | TriCase(D4, D4â€™) | P11.L0.H2\n",
        "  v4_c = tri_case(d4, d4d)\n",
        "\n",
        "  # V4.C5 | TriAdd(V4.C, V3.C4) | P11.L0.MLP\n",
        "  v4_c5 = tri_add(v4_c, v3_c4)\n",
        "\n",
        "  # A5 | (V4.C5 == 10) | P11.L1.MLP\n",
        "  a5 = 1 if v4_c5 == 10 else 0\n",
        "\n",
        "  # V4.BA | (D4 + D4') % 10 | P12.L0.H0 + H2\n",
        "  v4_ba = (d4 + d4d) % 10\n",
        "\n",
        "  # V3.C4 | TriAdd(TriCase(D3, D3â€™), TriAdd(V2.C,V1.C2)) | P12.L0.H1\n",
        "  v3_c4 = tri_add( tri_case(d3, d3d), tri_add(v2_c, v1_c2) )\n",
        "\n",
        "  # A4 | (V4.BA + V3.C4 / 10) % 10 | P12.L0.MLP and P12.L1.MLP\n",
        "  a4 = (v4_ba + (v3_c4 // 10)) % 10\n",
        "\n",
        "  #V3.BA | (D3 + D3') % 10 | P13.L0.H0 + H2\n",
        "  v3_ba = (d3 + d3d) % 10\n",
        "\n",
        "  # V2.C3 | TriAdd(V2.C,V1.C2) | P13.L0.H1\n",
        "  v2_c3 = tri_add(v2_c, v1_c2)\n",
        "\n",
        "  # A3 | (V3.BA + V2.C3 / 10) % 10 | P13.L0.MLP and P13.L1.MLP\n",
        "  a3 = (v3_ba + (v2_c3 // 10)) % 10\n",
        "\n",
        "  # V2.BA | (D2 + D2') % 10 | P14.L0.H0 + H2\n",
        "  v2_ba = (d2 + d2d) % 10\n",
        "\n",
        "  # V1.C2 | Copy from P10 | P14.L0.H1\n",
        "  # skip\n",
        "\n",
        "  # A2 | (V2.BA + V1.C2 / 10) % 10 | P14.L0.MLP and P14.L1.MLP\n",
        "  a2 = (v2_ba + (v1_c2 // 10)) % 10\n",
        "\n",
        "  # V1.BA | (D1 + D1') % 10 | P15.L0.H0 + H2\n",
        "  v1_ba = (d1 + d1d) % 10\n",
        "\n",
        "  # D0.MC | (D0 + D0') // 10 | P15.L0.H1\n",
        "  v0_mc = (d0 + d0d) // 10\n",
        "\n",
        "  # A1 | (V1.BA + D0.MC) % 10 | P15.L0.MLP and P15.L1.MLP\n",
        "  a1 = (v1_ba + v0_mc) % 10\n",
        "\n",
        "  # A0 | (D0 + D0') % 10 | P16.L0.H0 + H2 P16.L0.MLP and P16.L1.MLP\n",
        "  a0 = (d0 + d0d) % 10\n",
        "\n",
        "  return a5, a4, a3, a2, a1, a0\n",
        "\n",
        "\n",
        "def do_addition_question(question):\n",
        "  if cfg.n_digits == 5:\n",
        "    d4 = int(question[0])\n",
        "    d3 = int(question[1])\n",
        "    d2 = int(question[2])\n",
        "    d1 = int(question[3])\n",
        "    d0 = int(question[4])\n",
        "    d4d = int(question[6])\n",
        "    d3d = int(question[7])\n",
        "    d2d = int(question[8])\n",
        "    d1d = int(question[9])\n",
        "    d0d = int(question[10])\n",
        "\n",
        "    a5, a4, a3, a2, a1, a0 = addition_psuedo_code( d4, d3, d2, d1, d0, d4d, d3d, d2d, d1d, d0d)\n",
        "\n",
        "    d = d4 * 10000 + d3 * 1000 + d2 * 100 + d1 * 10 + d0\n",
        "    dd = d4d * 10000 + d3d * 1000 + d2d * 100 + d1d * 10 + d0d\n",
        "    a = a5 * 100000 + a4 * 10000 + a3 * 1000 + a2 * 100 + a1 * 10 + a0\n",
        "\n",
        "    if d + dd != a :\n",
        "      print(d4, d3, d2, d1, d0, \"+\" ,d4d, d3d, d2d, d1d, d0d, \"=\", a5, a4, a3, a2, a1, a0 )\n",
        "      print(\"Bad addition:\", d, \"+\", dd, \"=\", a, \"Should be\", d+dd, \"Delta\", d+dd-a)\n",
        "      return False\n",
        "\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nt7B0hdy-OZU"
      },
      "outputs": [],
      "source": [
        "def verify_mathematical_framework():\n",
        "  if cfg.n_digits == 5:\n",
        "    num_successes = 0;\n",
        "    num_fails = 0\n",
        "\n",
        "    num_batches = 1000000//cfg.batch_size\n",
        "    for epoch in range(num_batches):\n",
        "      tokens, _, _, _, _, _ = next(ds)\n",
        "\n",
        "      for i in range(cfg.batch_size):\n",
        "        if not do_addition_question(tokens[i]):\n",
        "          num_fails += 1\n",
        "\n",
        "      if num_fails > 0:\n",
        "        break\n",
        "\n",
        "      num_successes += cfg.batch_size\n",
        "      if epoch % 250 == 0:\n",
        "          print(\"Batch\", epoch, \"of\", num_batches, \"#Successes=\", num_successes)\n",
        "\n",
        "    print(\"successes\", num_successes, \"num_fails\", num_fails)\n",
        "\n",
        "\n",
        "#verify_mathematical_framework()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgCog0mYkYPV"
      },
      "source": [
        "# Part 21A : Set Up Interchange Interventions\n",
        "\n",
        "Here we test our mapping of our mathematical framework (causual abstraction) to the model attention heads.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8VoNc_ckfrJ"
      },
      "outputs": [],
      "source": [
        "class A_Config():\n",
        "  token_position : int = 15 # The token position we want to get/set. P8 to P11 contribute to A5 calculations\n",
        "  layer : int = 0 # The layer we want to get/set\n",
        "  heads = [] # The heads we want to get/set\n",
        "  threshold : int = 0.00001\n",
        "\n",
        "  hook_calls: int = 0\n",
        "  answer_failures : int = 0    # Failures of any digit\n",
        "\n",
        "  questions = []\n",
        "  store = []\n",
        "\n",
        "  null_hooks = []\n",
        "  get_hooks = []\n",
        "  put_hooks = []\n",
        "\n",
        "\n",
        "acfg = A_Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMdSybNpnU0m"
      },
      "outputs": [],
      "source": [
        "# Get and put attention head value hooks\n",
        "\n",
        "def a_null_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  acfg.hook_calls += 1\n",
        "  #print(\"In a_null_attn_z_hook\", value.shape)  # Get [1, 18, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "\n",
        "\n",
        "def a_get_l0_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 0:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In a_get_l0_attn_z_hook\", value.shape) # Get [1, 18, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "    acfg.store = value.clone()\n",
        "\n",
        "\n",
        "def a_get_l1_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 1:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In acfg.get_l1_attn_z_hook\", value.shape) # Get [1, 18, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "    acfg.store = value.clone()\n",
        "\n",
        "\n",
        "def a_put_l0_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 0:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In a_l0_attn_z_hook\", value.shape) # Get [1, 18, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, d_head\n",
        "    for head_index in acfg.heads:\n",
        "      value[:,acfg.token_position,head_index,:] = acfg.store[:,acfg.token_position,head_index,:].clone()\n",
        "\n",
        "\n",
        "def a_put_l1_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 1:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In a_put_l1_attn_z_hook\", value.shape) # Get [1, 18, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, d_head\n",
        "    for head_index in acfg.heads:\n",
        "      value[:,acfg.token_position,head_index,:] = acfg.store[:,acfg.token_position,head_index,:].clone()\n",
        "\n",
        "\n",
        "def a_reset(token_position, layer, heads):\n",
        "  global acfg\n",
        "\n",
        "  acfg.token_position = token_position\n",
        "  acfg.layer = layer\n",
        "  acfg.heads = heads\n",
        "\n",
        "  acfg.hook_calls = 0\n",
        "  acfg.answer_failures = 0\n",
        "\n",
        "  acfg.null_hooks = [(l_attn_hook_z_name[0], a_null_attn_z_hook)]\n",
        "  acfg.get_hooks = [(l_attn_hook_z_name[0], a_get_l0_attn_z_hook),(l_attn_hook_z_name[1], a_get_l1_attn_z_hook)]\n",
        "  acfg.put_hooks = [(l_attn_hook_z_name[0], a_put_l0_attn_z_hook),(l_attn_hook_z_name[1], a_put_l1_attn_z_hook)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SeIO06JnU7I"
      },
      "outputs": [],
      "source": [
        "def a_predict_question(description, the_hooks, always):\n",
        "  global acfg\n",
        "  global model\n",
        "\n",
        "  acfg.hook_calls = 0\n",
        "  acfg.answer_failures = 0\n",
        "\n",
        "  model.reset_hooks()\n",
        "  model.set_use_attn_result(True)\n",
        "\n",
        "  all_logits = model.run_with_hooks(acfg.questions.cuda(), return_type=\"logits\", fwd_hooks=the_hooks)\n",
        "  all_losses_raw, all_max_indices = logits_to_tokens_loss(all_logits, acfg.questions.cuda())\n",
        "\n",
        "  for question_num in range(acfg.questions.shape[0]):\n",
        "    loss_max = utils.to_numpy(loss_fn(all_losses_raw[question_num]).mean())\n",
        "\n",
        "    answer_str = tokens_to_string(all_max_indices[question_num])\n",
        "\n",
        "    match_str = \"\"\n",
        "    if loss_max > acfg.threshold:\n",
        "      acfg.answer_failures += 1\n",
        "      q = acfg.questions[question_num]\n",
        "      match_str = get_answer_impact( q, answer_str )\n",
        "    if match_str == \"\":\n",
        "      match_str = \"(none)\"\n",
        "\n",
        "    if always or (loss_max > acfg.threshold):\n",
        "      loss_str = \"(none)\" if loss_max < 1e-7 else str(loss_max)\n",
        "\n",
        "      print(description, \"  ModelPredicts:\", answer_str, \"  DigitsImpacted:\", match_str, \"  Loss:\", loss_str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk0gVCF9Gr5D"
      },
      "outputs": [],
      "source": [
        "def a_run_intervention_core(token_position, layer, heads, store_question, alter_question):\n",
        "  a_reset(token_position, layer, heads)\n",
        "\n",
        "  # Predict first question and store activation values (including the Vn.BA)\n",
        "  acfg.questions = make_questions([store_question])\n",
        "  a_predict_question(\"Unit test (null hook)\", acfg.null_hooks, False)\n",
        "  a_predict_question(\"Store activation\", acfg.get_hooks, False)\n",
        "\n",
        "  # Predict second question. Then rerun overriding Pn_Lm_Hp to give bad answer\n",
        "  acfg.questions = make_questions([alter_question])\n",
        "  a_predict_question(\"Unit test (null hook)\", acfg.null_hooks, False)\n",
        "  prompt = \"Intervening on P\" + str(token_position) + \".L\" + str(layer) + \".H\"\n",
        "  for head_index in acfg.heads:\n",
        "    prompt += str(head_index) + \",\"\n",
        "  a_predict_question(prompt, acfg.put_hooks, True)\n",
        "\n",
        "\n",
        "def a_run_intervention(description, token_position, layer, heads, store_question, alter_question):\n",
        "  if cfg.n_digits == 5 and cfg.n_layers == 2:\n",
        "    print(description)\n",
        "    a_run_intervention_core(token_position, layer, heads, store_question, alter_question)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bbeIfUxvLzl"
      },
      "source": [
        "# Part 21B : Run Interchange Interventions\n",
        "\n",
        "Here we test our mapping of our mathematical framework (casual abstraction) to the model attention heads.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFLdZkmEHhIo"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P8.L0.H1 performs V2.C = TriCase(D2, D2â€™) impacting A4 and A5 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [44444, 55555] # Sum is 099999. V2 has no MC.\n",
        "alter_question = [11111, 11111] # Sum is 022222. V2 has no MC.\n",
        "a_run_intervention(\"No V2.MC: No impact expected\", 8, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [77711, 22711] # Sum is 100422. V2 has MC\n",
        "alter_question = [44444, 55555] # Sum is 099999. V2 has no MC\n",
        "a_run_intervention(\"Insert V2.MC: Expect A54 digit impacts. Expect 109999.\", 8, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [17711, 22711] # Sum is 035422. V2 has MC\n",
        "alter_question = [ 4444,  5555] # Sum is 009999. V2 has no MC\n",
        "a_run_intervention(\"Insert V2.MC: Expect A4 digit impact. Expect 019999.\", 8, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P8.L0.H1 is: Based on D2 and D2'. Triggers on a V2 carry value. Provides \"carry 1\" used in A5 and A4 calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNtG_mlXeZKd"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P9.L0.H1 performs V1.C = TriCase(D1, D1â€™) impacting A5, A4 & A3 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [ 44444, 55555] # Sum is 099999. V1 has no MC.\n",
        "alter_question = [ 11111, 11111] # Sum is 022222. V1 has no MC\n",
        "a_run_intervention(\"No V1.MC: No impact expected\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11171, 11171] # Sum is 022342. V1 has MC\n",
        "alter_question = [ 44444, 55555] # Sum is 099999. V1 has no MC.\n",
        "a_run_intervention(\"Insert V1.MC: Expect A543 digit impacts. Expect 100999.\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11171, 11171] # Sum is 022342. V1 has MC\n",
        "alter_question = [  4444,  5555] # Sum is 009999. V1 has no MC\n",
        "a_run_intervention(\"Insert V1.MC: Expect A43 digit impacts. Expect 010999.\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11171, 11171] # Sum is 022342. V1 has MC\n",
        "alter_question = [   444,   555] # Sum is 000999. V1 has no MC\n",
        "a_run_intervention(\"Insert V1.MC: Expect A3 digit impact. Expect 001999.\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P9.L0.H1 is: Based on D1 and D1'. Triggers on a V1 carry value. Provides \"carry 1\" used in A5, A4 & A3 calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDt2LmNwiMGA"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P10.L0.H1 performs V1.C2 = TriAdd(V1.C, TriCase(D0, D0â€™)) impacting A5, A4, A3 & A2 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [ 11111, 33333] # Sum is 044444. V0 has no MC.\n",
        "alter_question = [ 44444, 55555] # Sum is 099999. V0 has no MC\n",
        "a_run_intervention(\"No impact expected\", 10, 0, [1], store_question, alter_question)\n",
        "# Results: No impact as expected\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [ 44444, 55555] # Sum is 099999. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC: Expect A5432 digit impacts. Expect 100099.\", 10, 0, [1], store_question, alter_question)\n",
        "# Results: Impact on A5432 as expected. Got expected value 100099\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [  4444,  5555] # Sum is 009999. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC: Expect A432 digit impacts. Expect 010099.\", 10, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [   444,   555] # Sum is 000999. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC: Expect A32 digit impacts. Expect 001099\", 10, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [    44,    55] # Sum is 000099. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC Expect A2 digit impacts. Expect 000199\", 10, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P10.L0.H1 is: Based on D0 and D0'. Triggers on a V0 carry value. Provides \"carry 1\" used in A5, A4, A3 & A2 calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxGCodzep7qV"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P11.L0.H1 performs V3.C4 = TriAdd(TriCase(D3, D3â€™),TriAdd(V2.C,V1.C2)) impacting A5 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [44444, 44444] # Sum is 088888. V3 sums to 8 (has no MC).\n",
        "alter_question = [11111, 11111] # Sum is 022222. V3 has no MC.\n",
        "a_run_intervention(\"No V3.MC: No impact expected\", 11, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [16111, 13111] # Sum is 032111. V3 sums to 9 (has no MC).\n",
        "alter_question = [44444, 55555] # Sum is 099999. V3 has no MC\n",
        "a_run_intervention(\"No V3.MC: No impact expected\", 11, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [16111, 16111] # Sum is 032111. V3 has MC\n",
        "alter_question = [44444, 55555] # Sum is 099999. V3 has no MC\n",
        "a_run_intervention(\"Insert V3.MC: Expect A5 digit impact. Expect 199999.\", 11, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P11.L0.H1 is: Based on D3 and D3'. Triggers on a V3 carry value. Provides \"carry 1\" used in A5 calculations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo55vCvCoMq7"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P11.L0.H2 performs V4.C = TriCase(D4, D4â€™) impacting A5 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [44444, 55555] # Sum is 099999. V4 has no MC.\n",
        "alter_question = [11111, 11111] # Sum is 022222. V4 has no MC.\n",
        "a_run_intervention(\"No V4.MC: No impact expected\", 11, 0, [2], store_question, alter_question)\n",
        "\n",
        "store_question = [71111, 71111] # Sum is 100422. V4 has MC\n",
        "alter_question = [44444, 55555] # Sum is 099999. V4 has no MC\n",
        "a_run_intervention(\"Insert V4.MC: Expect A5 digit impact. Expect 199999.\", 11, 0, [2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P9.L0.H2 is: Based on D4 and D4'. Triggers on a V4 carry value. Provides \"carry 1\" used in A5 calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jSE5S9UQFpn"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P12.L0.H0 and H2 performs V4.BA = (D4 + D4â€™) % 10 impacting A4 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [72222, 71111] # Sum is 143333\n",
        "alter_question = [12342, 56573] # Sum is 068915\n",
        "a_run_intervention(\"Override D4/D4'. Expect A4 digit impact. Expect 048915\", 12, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P12.L0.H0+H2 is: Adds D4 and D4'. Impacts A4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6UpIJbfPG6r"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P13.L0.H0 and H2 performs V3.BA = (D3 + D3â€™) % 10 impacting A3 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [23222, 13111] # Sum is 36333\n",
        "alter_question = [12342, 56573] # Sum is 68915\n",
        "a_run_intervention(\"Override D3/D3'. Expect A3 digit impact. Expect 66915\", 13, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P13.L0.H0+H2 is: Adds D3 and D3'. Impacts A3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXiOPyZ1ONcg"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P14.L0.H0 and H2 performs V2.BA = (D2 + D2â€™) % 10 impacting A2 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22322, 11311] # Sum is 33633. No V1.MC\n",
        "alter_question = [12342, 56573] # Sum is 68915. Has V1.MC\n",
        "a_run_intervention(\"Override D2/D2'. Expect A2 digit impact. Expect 68715\", 14, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "store_question = [22322, 11311] # Sum is 33633. No V1.MC\n",
        "alter_question = [12133, 56133] # Sum is 68266. No V1.MC\n",
        "a_run_intervention(\"Override D2/D2'. Expect A2 digit impact. Expect 68666\", 14, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P12.L0.H0 and H2 both impact A2, and together sum D2 and D2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAzB924mQkyN"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P14.L0.H1 calculates V1.C1 but also relies on P10.V1.C2, impacting A2 accuracy\")\n",
        "print()\n",
        "\n",
        "\n",
        "store_question = [55555, 44454] # Sum is 100009. Has V1.MC\n",
        "alter_question = [22222, 33333] # Sum is 055555. No V1.MC\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 055655\", 14, 0, [1], store_question, alter_question) # Get 055655. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 055655\", 10, 0, [1], store_question, alter_question) # Get 055555. No impact.\n",
        "\n",
        "store_question = [55590, 44490] # Sum is 100080. Has V1.MC\n",
        "alter_question = [12345, 54321] # Sum is 066666. No V1.MC\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 066766\", 14, 0, [1], store_question, alter_question) # Get 066766. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 066766\", 10, 0, [1], store_question, alter_question) # Get 066666. No impact.\n",
        "\n",
        "store_question = [12345, 54321] # Sum is 066666. No V1.MC\n",
        "alter_question = [55590, 44490] # Sum is 100080. Has V1.MC\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 100980\", 14, 0, [1], store_question, alter_question) # Get 100980. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 100980\", 10, 0, [1], store_question, alter_question) # Get 100080. No impact.\n",
        "\n",
        "# Above shows:\n",
        "# - P14.L0.H1 behaviour is different from P10.L0.H1 behaviour\n",
        "# - P14.L0.H1 does not simply copy P10.L0.H1 (although this would be a valid way to get perfect accuracy in A2)\n",
        "print()\n",
        "\n",
        "store_question = [12345, 54321] # Sum is 066666. No V1.MC\n",
        "alter_question = [55555, 44445] # Sum is 100000. Has V0.MC, V1.MC, V1.C2\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C2. Expect A2 digit impact. Expect 100900\", 14, 0, [1], store_question, alter_question) # Get 100900. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 099900\", 10, 0, [1], store_question, alter_question) # Get 099900. Correct\n",
        "\n",
        "store_question = [22222, 33333] # Sum is 055555. No V1.MC\n",
        "alter_question = [66663, 33337] # Sum is 100000. Has V0.MC, V1.MC, V1.C2\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C2. Expect A2 digit impact. Expect 100900\", 14, 0, [1], store_question, alter_question) # Get 100900. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 099900\", 10, 0, [1], store_question, alter_question) # Get 099900. Correct\n",
        "\n",
        "# Above shows:\n",
        "# - P14.L0.H1 does rely on P10.L0.H1 for V1.C2 information when V1.C != V1.C2\n",
        "# - P14.L0.H1 calculates V1.C information itself from D1+D1'.\n",
        "\n",
        "# Overall confirmed: P14.L0.H1 calculates V1.C1 but also relies on P10.V1.C2 when V1.C != V1.C2. Impacts A2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJiVBPZe6DUe"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P15.L0.H0 and H2 performs V1.BA = (D1 + D1â€™) % 10 impacting A1 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22242, 11141] # Sum is 33383. No V0.MC\n",
        "alter_question = [12322, 56523] # Sum is 68845. No V0.MC\n",
        "a_run_intervention(\"Override D1/D1'. Expect A1 digit impact. Expect 68885\", 15, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P15.L0.H0 and H2 both impact A1, and together sum D1 and D1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVrX9QmOnVCM"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P15.L0.H1 performs V0.MC = (D0 + D0â€™) / 10 impacting A1 (A one) accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22244, 11149] # Sum is 33393. Has V0.MC\n",
        "alter_question = [12342, 56513] # Sum is 68855. No V0.MC\n",
        "a_run_intervention(\"Override D0.MC. Expect A1 digit impact. Expect 68865\", 15, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Now test counter-claim that an intervention where both questions do NOT generate a D0.MC has NO impact on A1\n",
        "store_question = [22242, 11141] # Sum is 33383. No V0.MC\n",
        "alter_question = [12342, 56523] # Sum is 68865. No V0.MC\n",
        "a_run_intervention(\"No impact expected\", 15, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P15.L0.H1: Triggers when D0 + D0' > 10. Impacts A1 digit by 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gM8TpWeyysU"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P16.L0.H0 and H2 performs D0.BA = (D0 + D0â€™) % 10 impacting A0 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22225, 11114] # Sum is 33339\n",
        "alter_question = [12342, 56563] # Sum is 68905\n",
        "a_run_intervention(\"Override D0/D0'. Expect A0 digit impact. Expect 68909\", 16, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "store_question = [22228, 11119] # Sum is 33347\n",
        "alter_question = [12342, 56563] # Sum is 68905\n",
        "a_run_intervention(\"Override D0/D0'. Expect A0 digit impact. Expect 68907\", 16, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P16.L0.H0 and H2 both impact A0, and together sum D0 and D0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgq2wyfURJCp"
      },
      "source": [
        "# Part 22: Ablate each NEURON in each useful MLP layer. What is impact on loss?\n",
        "\n",
        "Uses n_ prefix. Determines which neurons are useful, so we can focus on them in Part 25 & manually view them.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McYRdEg9SYGS"
      },
      "outputs": [],
      "source": [
        "class N_Config():\n",
        "  position : int = 0  # zero-based token-position to ablate\n",
        "  layer : int = 0 # zero-based layer to ablate. 0 to cfg.n_layers\n",
        "  neuron : int = 0 # zero-based neuron to ablate. 0 to cfg.d_mlp\n",
        "  questions = varied_questions\n",
        "  output = PrettyTable()\n",
        "  hook_calls : int = 0\n",
        "\n",
        "\n",
        "ncfg = N_Config()\n",
        "\n",
        "\n",
        "def n_reset():\n",
        "  global ncfg\n",
        "\n",
        "  ncfg.output = PrettyTable()\n",
        "  ncfg.output.field_names = [\"Position\", \"MLP Layer\", \"Neuron\", \"% Fails\", \"% Fails by Case\", \"# Fails by Patterns\"]\n",
        "  ncfg.hook_calls = 0\n",
        "\n",
        "\n",
        "def n_mlp_hook_post(value, hook):\n",
        "  global ncfg\n",
        "\n",
        "  ncfg.hook_calls += 1\n",
        "  #print( \"In n_mlp_hook_post\", value.shape) # Get [1, 18, 2040] = ???, cfg.n_ctx, cfg.d_mlp\n",
        "\n",
        "  # Mean ablate. Copy the mean resid post values in position N to the MLP\n",
        "  value[:,ncfg.position,ncfg.neuron] =  mean_mlp_hook_post[:,ncfg.position,ncfg.neuron].clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QynhCl3u5Kp"
      },
      "outputs": [],
      "source": [
        "class UsefulNeuron():\n",
        "  position : int = 0  # zero-based token-position to ablate\n",
        "  layer : int = 0 # zero-based layer to ablate. 0 to cfg.n_layers\n",
        "  neuron : int = 0 # zero-based neuron to ablate. 0 to cfg.d_mlp\n",
        "\n",
        "\n",
        "useful_neurons = []\n",
        "\n",
        "\n",
        "def n_perform_core(show_all = False):\n",
        "  global ncfg\n",
        "\n",
        "  the_hook = [(l_mlp_hook_post_name[ncfg.layer], n_mlp_hook_post)]\n",
        "  q_predict_questions(ncfg.questions, the_hook)\n",
        "\n",
        "  num_fails = q_total_complexity_fails()\n",
        "  if show_all or (num_fails > 0):\n",
        "    perc_fails = round(100 * num_fails / ncfg.questions.shape[0])\n",
        "    (pattern_results, top_pattern) = get_sorted_impact_fails()\n",
        "\n",
        "    ncfg.output.add_row([str(ncfg.position), str(ncfg.layer), str(ncfg.neuron), perc_fails, q_get_complexity_fails(), pattern_results])\n",
        "\n",
        "    useful_neuron = UsefulNeuron()\n",
        "    useful_neuron.position = ncfg.position\n",
        "    useful_neuron.layer = ncfg.layer\n",
        "    useful_neuron.neuron = ncfg.neuron\n",
        "\n",
        "    useful_neurons += [useful_neuron]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFCiE9yvSFNR"
      },
      "outputs": [],
      "source": [
        "def run_neurons():\n",
        "  q0 = make_s0_questions()\n",
        "  q1 = make_s1_questions()\n",
        "  q2 = make_s2_questions()\n",
        "  q3 = make_s3_questions()\n",
        "  q4 = make_s4_questions()\n",
        "  ncfg.questions = torch.vstack((q0.cuda(), q1.cuda(), q2.cuda(), q3.cuda(), q4.cuda()))\n",
        "  print( \"# questions\", ncfg.questions.shape[0], \"# usefulcells\", len(ucfg.useful_cells))\n",
        "\n",
        "  for useful_cell in ucfg.useful_cells:\n",
        "    if not useful_cell.is_head():\n",
        "      n_reset()\n",
        "      ncfg.position = useful_cell.position\n",
        "      ncfg.layer = useful_cell.layer\n",
        "\n",
        "      # For each useful MLP layer, check the neurons.\n",
        "      for the_neuron in range(cfg.d_mlp):\n",
        "        ncfg.neuron = the_neuron\n",
        "        n_perform_core()\n",
        "\n",
        "      print(ncfg.output.get_formatted_string(out_format=cfg.table_out_format))\n",
        "\n",
        "#run_neurons()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTs6Cu55jB7y"
      },
      "source": [
        "#Part 25: MLP Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YviVHnBRjDcs"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "# number of questions in batch that generated sample_cache\n",
        "num_questions = ncfg.questions.shape[0]\n",
        "\n",
        "\n",
        "def get_mlp_data(data_set_name):\n",
        "\n",
        "  data_set = sample_cache[data_set_name]\n",
        "  # print( data_set_name + \" shape\", data_set.shape) # 239, 18, 2040 = num_questions, n_ctx, d_mlp\n",
        "\n",
        "  raw_data = data_set[:,-3]\n",
        "  # print( \"raw_data shape\", raw_data.shape) # 239, 2040 = num_questions, d_mlp\n",
        "\n",
        "  answer = einops.rearrange(raw_data, \"(x y) d_mlp -> x y d_mlp\", x=num_questions).cpu().numpy()\n",
        "  # print( \"answer shape\", answer.shape) # 239, 1, 2040 = num_questions, ??, d_mlp\n",
        "\n",
        "  return answer\n",
        "\n",
        "\n",
        "l0_mlp_hook_pre_sq = get_mlp_data(utils.get_act_name('pre', 0))\n",
        "l0_mlp_hook_post_sq = get_mlp_data(utils.get_act_name('post', 0))\n",
        "l1_mlp_hook_pre_sq = get_mlp_data(utils.get_act_name('pre', 1))\n",
        "l1_mlp_hook_post_sq = get_mlp_data(utils.get_act_name('post', 1))\n",
        "\n",
        "\n",
        "def plot_mlp_neuron_activation(pos: int):\n",
        "    clear_output()\n",
        "\n",
        "    l0_mlp_pre_data = l0_mlp_hook_pre_sq[:,:,pos]\n",
        "    l0_mlp_post_data = l0_mlp_hook_post_sq[:,:,pos]\n",
        "    l1_mlp_pre_data = l1_mlp_hook_pre_sq[:,:,pos]\n",
        "    l1_mlp_post_data = l1_mlp_hook_post_sq[:,:,pos]\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(8,4))\n",
        "\n",
        "    plot = axs[0].imshow(l1_mlp_pre_data, cmap='magma', vmin=0, vmax=1)\n",
        "    cbar = plt.colorbar(plot, fraction=0.1)\n",
        "    cbar.set_label(r'l0_mlp_pre_data {}'.format(pos))\n",
        "    #axs[0].set_ylim(-0.5, 99.5)\n",
        "    #axs[0].set_yticks(range(100), labels=range(100), size=5.5);\n",
        "    #axs[0].set_xticks(range(100), labels=range(100), size=5.5, rotation='vertical');\n",
        "\n",
        "    plot = axs[1].imshow(l1_mlp_post_data, cmap='magma', vmin=0, vmax=1)\n",
        "    cbar = plt.colorbar(plot, fraction=0.1)\n",
        "    cbar.set_label(r'l0_mlp_post_data {}'.format(pos))\n",
        "    #axs[0].set_ylim(-0.5, 99.5)\n",
        "    #axs[0].set_yticks(range(100), labels=range(100), size=5.5);\n",
        "    #axs[0].set_xticks(range(100), labels=range(100), size=5.5, rotation='vertical');\n",
        "\n",
        "\n",
        "interact(plot_mlp_neuron_activation, pos=widgets.IntText(value=0, description='Index:'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "ldGPkaokJQM5",
        "pTd3nmsMJV5T",
        "P8RfHXneJw6n",
        "ZHiJhch4KCej",
        "-KJhCxFtNKfm",
        "fGxoBWHNKRf0",
        "fPH-deQUIOGY",
        "FyK7QeUjLLFm",
        "904WBkTOLg_5",
        "-u5w87NMP6lm",
        "M5ZxVECzcEkW",
        "BhhTk0tmvmQ0",
        "lSxC4S2W7jn-",
        "XO3kH-aQyM3U",
        "Kgq2wyfURJCp",
        "lTs6Cu55jB7y"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}